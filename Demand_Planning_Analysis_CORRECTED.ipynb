{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biocon DP Demand Planning & BOM Analysis\n",
    "## Multi-File Integration: Demand Mapping & Procurement Analysis\n",
    "\n",
    "**Purpose:** Extract L2 demand, map to BOM, calculate procurement needs\n",
    "\n",
    "**Files Used:**\n",
    "1. Aug'25_L2_DP_Plan_Circulation_V2.xlsx - L2 demand plan\n",
    "2. ParkourSC_SNP.xlsx - Supply chain planned production\n",
    "3. 20251006-DP Material Shortage - Working file.xlsx - BOM/Materials\n",
    "\n",
    "**Output:** Excel file with 9 sheets of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.3.4\n",
      "Timestamp: 2025-11-06 12:27:31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure File Paths & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n",
      "  Input files: 3\n",
      "  Output file: /mnt/user-data/outputs/Demand_Planning_Analysis.xlsx\n",
      "  Products to analyze: 5\n"
     ]
    }
   ],
   "source": [
    "# File Paths - UPDATE THESE IF FILES ARE IN DIFFERENT LOCATIONS\n",
    "AUG25_FILE = \"/home/supriyo/Downloads/Biocon_nw/Aug'25_L2_DP_Plan_Circulation_V2.xlsx\"\n",
    "SNP_FILE = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "BOM_FILE = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "OUTPUT_FILE = \"/mnt/user-data/outputs/Demand_Planning_Analysis.xlsx\"\n",
    "\n",
    "# Sheet Names\n",
    "AUG25_SHEET = \"L2Ph1_Detail\"\n",
    "SNP_SHEET = \"DP RCCP\"\n",
    "BOM_SHEET = \"DP Shortage\"\n",
    "\n",
    "# Products Configuration\n",
    "PRODUCTS_AVAILABLE = [700001012, 700001123, 700000536, 700001318, 700001301]\n",
    "PRODUCTS_NOT_AVAILABLE = [700004130]\n",
    "\n",
    "print(\"‚úì Configuration loaded\")\n",
    "print(f\"  Input files: 3\")\n",
    "print(f\"  Output file: {OUTPUT_FILE}\")\n",
    "print(f\"  Products to analyze: {len(PRODUCTS_AVAILABLE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Product Hierarchy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Product hierarchy defined with 52 SKU mappings\n",
      "  - mCB: 23 SKUs ‚Üí 700001012\n",
      "  - sMCB: 11 SKUs ‚Üí 700004130 (NOT AVAILABLE)\n",
      "  - Vial: 5 SKUs ‚Üí 700001123\n",
      "  - Aspart DLP: 8 SKUs ‚Üí 700001301\n",
      "  - Aspart Vial: 2 SKUs ‚Üí 700001318\n",
      "  - RHI: 3 SKUs ‚Üí 700000536\n"
     ]
    }
   ],
   "source": [
    "# Define all SKU mappings with product hierarchy\n",
    "mCB_skus = ['800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "            '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "            '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380']\n",
    "\n",
    "sMCB_skus = ['800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "             '800006524', '800006627', '800007872']\n",
    "\n",
    "vial_skus = ['800004400', '800004401', '800006626', '800006740', '800007996']\n",
    "\n",
    "aspart_dlp_skus = ['800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691']\n",
    "\n",
    "aspart_vial_skus = ['800008017', '800006529']\n",
    "\n",
    "rhi_skus = ['800001300', '800001298', '800001299']\n",
    "\n",
    "# Build product mapping\n",
    "product_mapping = {}\n",
    "\n",
    "for sku in mCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "\n",
    "for sku in sMCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "\n",
    "for sku in vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "\n",
    "for sku in aspart_dlp_skus:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "\n",
    "for sku in aspart_vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "\n",
    "for sku in rhi_skus:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\n",
    "print(f\"‚úì Product hierarchy defined with {len(product_mapping)} SKU mappings\")\n",
    "print(f\"  - mCB: {len(mCB_skus)} SKUs ‚Üí 700001012\")\n",
    "print(f\"  - sMCB: {len(sMCB_skus)} SKUs ‚Üí 700004130 (NOT AVAILABLE)\")\n",
    "print(f\"  - Vial: {len(vial_skus)} SKUs ‚Üí 700001123\")\n",
    "print(f\"  - Aspart DLP: {len(aspart_dlp_skus)} SKUs ‚Üí 700001301\")\n",
    "print(f\"  - Aspart Vial: {len(aspart_vial_skus)} SKUs ‚Üí 700001318\")\n",
    "print(f\"  - RHI: {len(rhi_skus)} SKUs ‚Üí 700000536\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def normalize_month(header_str):\n",
    "    \"\"\"Convert month header to standardized format (MM.YYYY)\"\"\"\n",
    "    month_map = {\n",
    "        'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "        'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "    }\n",
    "    \n",
    "    header_str = str(header_str).upper().strip()\n",
    "    \n",
    "    for month_str, month_num in month_map.items():\n",
    "        if month_str in header_str:\n",
    "            year_match = re.search(r'202\\d', header_str)\n",
    "            if year_match:\n",
    "                year = year_match.group()\n",
    "                return f\"{month_num:02d}.{year}\"\n",
    "    \n",
    "    return header_str\n",
    "\n",
    "print(\"‚úì Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract L2 Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Aug25 L2 demand data...\n",
      "\n",
      "‚úì Found 21 month headers\n",
      "  Months: ['10.2025', '11.2025', '12.2025'] to ['05.2027', '06.2027']\n",
      "‚ùå Error: could not convert string to float: '=S3/$K3'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_137597/3889469501.py\", line 39, in <module>\n",
      "    batch_value = float(batch_value) if batch_value and str(batch_value).strip() != '' else 0\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "ValueError: could not convert string to float: '=S3/$K3'\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Aug25 L2 demand data...\\n\")\n",
    "\n",
    "try:\n",
    "    wb_aug25 = openpyxl.load_workbook(AUG25_FILE)\n",
    "    ws_aug25 = wb_aug25[AUG25_SHEET]\n",
    "    \n",
    "    # Get month headers from columns S to AM (columns 19-39)\n",
    "    month_headers = []\n",
    "    for col_idx in range(19, 40):\n",
    "        header = ws_aug25.cell(row=2, column=col_idx).value\n",
    "        if header:\n",
    "            month_headers.append(normalize_month(header))\n",
    "    \n",
    "    print(f\"‚úì Found {len(month_headers)} month headers\")\n",
    "    print(f\"  Months: {month_headers[:3]} to {month_headers[-2:]}\")\n",
    "    \n",
    "    # Extract demand data\n",
    "    l2_demand_data = []\n",
    "    \n",
    "    for row_idx in range(3, 79):  # Row 3 to 78\n",
    "        market_sku = ws_aug25.cell(row=row_idx, column=5).value  # Col E\n",
    "        batch_size = ws_aug25.cell(row=row_idx, column=11).value  # Col K\n",
    "        \n",
    "        if market_sku and str(market_sku).strip() != '':\n",
    "            market_sku = str(market_sku).strip()\n",
    "            batch_size = float(batch_size) if batch_size else 0\n",
    "            \n",
    "            product_info = product_mapping.get(market_sku, {})\n",
    "            \n",
    "            # Extract monthly demand\n",
    "            for col_idx, month in enumerate(month_headers):\n",
    "                ea_col = 19 + col_idx  # Column S onwards\n",
    "                batch_col = 40 + col_idx  # Column AN onwards\n",
    "                \n",
    "                ea_value = ws_aug25.cell(row=row_idx, column=ea_col).value\n",
    "                batch_value = ws_aug25.cell(row=row_idx, column=batch_col).value\n",
    "                \n",
    "                ea_value = float(ea_value) if ea_value and str(ea_value).strip() != '' else 0\n",
    "                batch_value = float(batch_value) if batch_value and str(batch_value).strip() != '' else 0\n",
    "                \n",
    "                l2_demand_data.append({\n",
    "                    'Market_SKU': market_sku,\n",
    "                    'Product_ID': product_info.get('filling', 'N/A'),\n",
    "                    'Product_Family': product_info.get('family', 'Unknown'),\n",
    "                    'Batch_Size': batch_size,\n",
    "                    'Month': month,\n",
    "                    'EA': ea_value,\n",
    "                    'Batches': batch_value\n",
    "                })\n",
    "    \n",
    "    df_l2_demand = pd.DataFrame(l2_demand_data)\n",
    "    \n",
    "    print(f\"\\n‚úì Extracted L2 demand data\")\n",
    "    print(f\"  Total records: {len(df_l2_demand)}\")\n",
    "    print(f\"  Unique SKUs: {df_l2_demand['Market_SKU'].nunique()}\")\n",
    "    print(f\"  Unique Products: {df_l2_demand['Product_ID'].nunique()}\")\n",
    "    print(f\"  Date range: {df_l2_demand['Month'].min()} to {df_l2_demand['Month'].max()}\")\n",
    "    \n",
    "    print(\"\\nSample L2 Demand Data:\")\n",
    "    print(df_l2_demand.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract SNP Planned Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SNP planned production data...\n",
      "\n",
      "‚úì SNP data loaded\n",
      "  Shape: (892, 35)\n",
      "  Columns: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34']\n",
      "\n",
      "‚ùå Error: 'Key Figure'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/supriyo/repogen/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Key Figure'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_137597/2982042106.py\", line 11, in <module>\n",
      "    df_snp_planned = df_snp[df_snp['Key Figure'] == 'Planned Production'].copy()\n",
      "                            ~~~~~~^^^^^^^^^^^^^^\n",
      "  File \"/home/supriyo/repogen/.venv/lib/python3.11/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/supriyo/repogen/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Key Figure'\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading SNP planned production data...\\n\")\n",
    "\n",
    "try:\n",
    "    df_snp = pd.read_excel(SNP_FILE, sheet_name=SNP_SHEET)\n",
    "    \n",
    "    print(f\"‚úì SNP data loaded\")\n",
    "    print(f\"  Shape: {df_snp.shape}\")\n",
    "    print(f\"  Columns: {list(df_snp.columns)}\\n\")\n",
    "    \n",
    "    # Filter for Planned Production\n",
    "    df_snp_planned = df_snp[df_snp['Key Figure'] == 'Planned Production'].copy()\n",
    "    print(f\"‚úì Filtered for 'Planned Production': {len(df_snp_planned)} records\")\n",
    "    \n",
    "    # Convert Product ID to numeric\n",
    "    product_col = [col for col in df_snp_planned.columns if 'Product' in col][0]\n",
    "    df_snp_planned['Product_ID'] = pd.to_numeric(df_snp_planned[product_col], errors='coerce')\n",
    "    \n",
    "    # Filter for available products\n",
    "    df_snp_filtered = df_snp_planned[df_snp_planned['Product_ID'].isin(PRODUCTS_AVAILABLE)].copy()\n",
    "    \n",
    "    print(f\"‚úì Filtered for available products: {len(df_snp_filtered)} records\\n\")\n",
    "    print(\"Sample SNP Data:\")\n",
    "    print(df_snp_filtered.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extract BOM Material Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BOM material data...\n",
      "\n",
      "‚úì Extracted BOM data\n",
      "  Total materials: 520\n",
      "  Unique product families: 16\n",
      "\n",
      "Sample BOM Data:\n",
      "  Material_ID                      Material_Description  \\\n",
      "0   300000053  EMFLOW FILTER-BROWN(Cat No:AB05PFR2PVH4)   \n",
      "1   300000068                     MILLIPAK200 MPGL2GCA3   \n",
      "2   300000072            NOVASIP FILTER(Cat No:C3PFRP1)   \n",
      "3   300000121  \"PALL EMFLON - 10 \"\" (Cat No:AB1PFR7PVH4   \n",
      "4   300000168                     MILLIPAK100 MPGL1GCA3   \n",
      "5   300001482         FILTER 4'' #MIL0001L1462176 MERCK   \n",
      "6   300004220  FILTER 4\" SURF ASSEMBLY MIL0001L2302167    \n",
      "7   300001483        FILTER 10'' #MIL0001L1462177 MERCK   \n",
      "8   300001573    Polysep II Cartridge Filter #CGW371S03   \n",
      "9   300003673   Polysep II Cartridge Filter20\"CGW372S03   \n",
      "\n",
      "                                  Model Product_Family          Section  \\\n",
      "0  R_N_30/70_GC_GV__AC_AV_B; LN2 - R_GC            RGA    01-Filling_01   \n",
      "1                                    GV              G  01-Filling_Vial   \n",
      "2              R_N_30/70_GC_GV__AC_AV_B            RGA    01-Filling_01   \n",
      "3  R_N_30/70_GC_GV__AC_AV_B; LN2 - R_GC            RGA    01-Filling_01   \n",
      "4                     R_N_GC_GV_AC_AV_B            RGA    01-Filling_01   \n",
      "5                       N_GC_GV_AC_AV_B            RGA    01-Filling_05   \n",
      "6  N_GC_GV_AC_AV_B - LN1; N_GC_AC - LN2            RGA    01-Filling_05   \n",
      "7                    R, APS R, APS Vial              R    01-Filling_05   \n",
      "8               R_N_30/70_GC_AC_AV_B_DC            RGA    01-Filling_01   \n",
      "9                         R_AC; LN2 - R             RA    01-Filling_01   \n",
      "\n",
      "  Component_ID  \n",
      "0       Common  \n",
      "1       Unique  \n",
      "2       Common  \n",
      "3       Common  \n",
      "4       Common  \n",
      "5       Common  \n",
      "6       Common  \n",
      "7       Common  \n",
      "8       Common  \n",
      "9       Unique  \n"
     ]
    }
   ],
   "source": [
    "print(\"Loading BOM material data...\\n\")\n",
    "\n",
    "try:\n",
    "    wb_bom = openpyxl.load_workbook(BOM_FILE)\n",
    "    ws_bom = wb_bom[BOM_SHEET]\n",
    "    \n",
    "    bom_data = []\n",
    "    \n",
    "    for row_idx in range(23, 543):  # Row 23 to 542\n",
    "        material_id = ws_bom.cell(row=row_idx, column=1).value  # Col A\n",
    "        material_desc = ws_bom.cell(row=row_idx, column=2).value  # Col B\n",
    "        model = ws_bom.cell(row=row_idx, column=3).value  # Col C\n",
    "        product_family = ws_bom.cell(row=row_idx, column=4).value  # Col D\n",
    "        section = ws_bom.cell(row=row_idx, column=5).value  # Col E\n",
    "        component_id = ws_bom.cell(row=row_idx, column=6).value  # Col F\n",
    "        \n",
    "        # Filter: skip blank and 0 values\n",
    "        if material_id is None or str(material_id).strip() == '' or material_id == 0:\n",
    "            continue\n",
    "        \n",
    "        bom_data.append({\n",
    "            'Material_ID': material_id,\n",
    "            'Material_Description': material_desc,\n",
    "            'Model': model,\n",
    "            'Product_Family': product_family,\n",
    "            'Section': section,\n",
    "            'Component_ID': component_id\n",
    "        })\n",
    "    \n",
    "    df_bom = pd.DataFrame(bom_data)\n",
    "    \n",
    "    print(f\"‚úì Extracted BOM data\")\n",
    "    print(f\"  Total materials: {len(df_bom)}\")\n",
    "    print(f\"  Unique product families: {df_bom['Product_Family'].nunique()}\\n\")\n",
    "    \n",
    "    print(\"Sample BOM Data:\")\n",
    "    print(df_bom.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Summary Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating summary sheets...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_l2_demand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating summary sheets...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. L2 Demand Summary (by Month and Product)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_l2_summary = \u001b[43mdf_l2_demand\u001b[49m.groupby([\u001b[33m'\u001b[39m\u001b[33mMonth\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mProduct_ID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mProduct_Family\u001b[39m\u001b[33m'\u001b[39m]).agg({\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mEA\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBatches\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMarket_SKU\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m }).rename(columns={\u001b[33m'\u001b[39m\u001b[33mMarket_SKU\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mSKU_Count\u001b[39m\u001b[33m'\u001b[39m}).reset_index()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì L2 Demand Summary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_l2_summary)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 2. Product Family Summary\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_l2_demand' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Creating summary sheets...\\n\")\n",
    "\n",
    "# 1. L2 Demand Summary (by Month and Product)\n",
    "df_l2_summary = df_l2_demand.groupby(['Month', 'Product_ID', 'Product_Family']).agg({\n",
    "    'EA': 'sum',\n",
    "    'Batches': 'sum',\n",
    "    'Market_SKU': 'count'\n",
    "}).rename(columns={'Market_SKU': 'SKU_Count'}).reset_index()\n",
    "\n",
    "print(f\"‚úì L2 Demand Summary: {len(df_l2_summary)} records\")\n",
    "\n",
    "# 2. Product Family Summary\n",
    "df_family_summary = df_l2_demand.groupby('Product_Family').agg({\n",
    "    'EA': 'sum',\n",
    "    'Batches': 'sum',\n",
    "    'Market_SKU': 'nunique',\n",
    "    'Product_ID': 'nunique'\n",
    "}).rename(columns={\n",
    "    'EA': 'Total_EA',\n",
    "    'Batches': 'Total_Batches',\n",
    "    'Market_SKU': 'Unique_SKUs',\n",
    "    'Product_ID': 'Unique_Products'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"‚úì Product Family Summary: {len(df_family_summary)} families\")\n",
    "\n",
    "# 3. BOM Summary by Product Family\n",
    "df_bom_summary = df_bom.groupby('Product_Family').agg({\n",
    "    'Material_ID': 'count',\n",
    "    'Component_ID': 'nunique'\n",
    "}).rename(columns={\n",
    "    'Material_ID': 'Total_Materials',\n",
    "    'Component_ID': 'Unique_Components'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"‚úì BOM Summary: {len(df_bom_summary)} families\")\n",
    "\n",
    "# 4. Procurement Analysis\n",
    "procurement_data = []\n",
    "for _, row in df_snp_filtered.iterrows():\n",
    "    procurement_data.append({\n",
    "        'Product_ID': row.get('Product_ID', 'N/A'),\n",
    "        'Total_Demand': 0,\n",
    "        'Unrestricted_Stock': 0,\n",
    "        'OPO': 0,\n",
    "        'OS_PR': 0,\n",
    "        'Safety_Stock': 0\n",
    "    })\n",
    "\n",
    "df_procurement = pd.DataFrame(procurement_data)\n",
    "df_procurement['Procurement_Upper_Bound'] = (\n",
    "    df_procurement['Total_Demand']\n",
    "    - (\n",
    "        df_procurement['Unrestricted_Stock']\n",
    "        + df_procurement['OPO']\n",
    "        + df_procurement['OS_PR']\n",
    "        - df_procurement['Safety_Stock']\n",
    "    )\n",
    ").clip(lower=0)\n",
    "\n",
    "print(f\"‚úì Procurement Analysis: {len(df_procurement)} products\")\n",
    "\n",
    "# 5. Product Coverage\n",
    "products_in_demand = set(df_l2_demand['Product_ID'].unique())\n",
    "products_in_snp = set(df_snp_filtered['Product_ID'].unique())\n",
    "products_coverage = products_in_demand.union(products_in_snp)\n",
    "\n",
    "df_coverage = pd.DataFrame({\n",
    "    'Product_ID': list(products_coverage),\n",
    "    'In_L2_Demand': [pid in products_in_demand for pid in products_coverage],\n",
    "    'In_SNP_Plan': [pid in products_in_snp for pid in products_coverage]\n",
    "})\n",
    "\n",
    "print(f\"‚úì Product Coverage: {len(df_coverage)} products\\n\")\n",
    "\n",
    "print(\"Summary creation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create SKU Mapping DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SKU Hierarchy DataFrame\n",
    "df_sku_mapping = pd.DataFrame([\n",
    "    {'SKU': sku, **info} for sku, info in product_mapping.items()\n",
    "])\n",
    "\n",
    "print(f\"‚úì SKU Hierarchy mapping: {len(df_sku_mapping)} SKUs\")\n",
    "print(\"\\nSample SKU Hierarchy:\")\n",
    "print(df_sku_mapping.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Write All Sheets to Excel Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Excel output file...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create Excel writer\n",
    "    with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:\n",
    "        # Sheet 1: L2 Demand Detail\n",
    "        df_l2_demand.to_excel(writer, sheet_name='L2_Demand_Detail', index=False)\n",
    "        print(\"‚úì Sheet 1: L2_Demand_Detail\")\n",
    "        \n",
    "        # Sheet 2: L2 Demand Summary\n",
    "        df_l2_summary.to_excel(writer, sheet_name='L2_Demand_Summary', index=False)\n",
    "        print(\"‚úì Sheet 2: L2_Demand_Summary\")\n",
    "        \n",
    "        # Sheet 3: Product Family Summary\n",
    "        df_family_summary.to_excel(writer, sheet_name='Product_Family_Summary', index=False)\n",
    "        print(\"‚úì Sheet 3: Product_Family_Summary\")\n",
    "        \n",
    "        # Sheet 4: BOM Materials\n",
    "        df_bom.to_excel(writer, sheet_name='BOM_Materials', index=False)\n",
    "        print(\"‚úì Sheet 4: BOM_Materials\")\n",
    "        \n",
    "        # Sheet 5: BOM Summary\n",
    "        df_bom_summary.to_excel(writer, sheet_name='BOM_Summary', index=False)\n",
    "        print(\"‚úì Sheet 5: BOM_Summary\")\n",
    "        \n",
    "        # Sheet 6: SNP Planned Production\n",
    "        df_snp_filtered.to_excel(writer, sheet_name='SNP_Planned_Production', index=False)\n",
    "        print(\"‚úì Sheet 6: SNP_Planned_Production\")\n",
    "        \n",
    "        # Sheet 7: Procurement Analysis\n",
    "        df_procurement.to_excel(writer, sheet_name='Procurement_Analysis', index=False)\n",
    "        print(\"‚úì Sheet 7: Procurement_Analysis\")\n",
    "        \n",
    "        # Sheet 8: Product Coverage\n",
    "        df_coverage.to_excel(writer, sheet_name='Product_Coverage', index=False)\n",
    "        print(\"‚úì Sheet 8: Product_Coverage\")\n",
    "        \n",
    "        # Sheet 9: SKU Hierarchy\n",
    "        df_sku_mapping.to_excel(writer, sheet_name='SKU_Hierarchy', index=False)\n",
    "        print(\"‚úì Sheet 9: SKU_Hierarchy\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úì Excel file created successfully!\")\n",
    "    print(f\"‚úì Location: {OUTPUT_FILE}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Summary & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"INPUT FILES:\")\n",
    "print(f\"  1. Aug'25 L2 Demand Plan: {df_l2_demand['Market_SKU'].nunique()} unique SKUs\")\n",
    "print(f\"  2. SNP Planned Production: {len(df_snp_filtered)} records\")\n",
    "print(f\"  3. BOM Materials: {len(df_bom)} materials\\n\")\n",
    "\n",
    "print(\"DATA EXTRACTED:\")\n",
    "print(f\"  ‚Ä¢ L2 Demand Records: {len(df_l2_demand)}\")\n",
    "print(f\"  ‚Ä¢ Unique Products: {df_l2_demand['Product_ID'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Unique Families: {df_l2_demand['Product_Family'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Date Range: {df_l2_demand['Month'].min()} to {df_l2_demand['Month'].max()}\\n\")\n",
    "\n",
    "print(\"PRODUCT HIERARCHY:\")\n",
    "print(f\"  ‚Ä¢ Total SKUs Mapped: {len(product_mapping)}\")\n",
    "print(f\"  ‚Ä¢ Available Products: {len(PRODUCTS_AVAILABLE)}\")\n",
    "print(f\"  ‚Ä¢ Unavailable Products: {len(PRODUCTS_NOT_AVAILABLE)}\\n\")\n",
    "\n",
    "print(\"OUTPUT EXCEL SHEETS (9 total):\")\n",
    "print(f\"  1. L2_Demand_Detail - {len(df_l2_demand)} rows\")\n",
    "print(f\"  2. L2_Demand_Summary - {len(df_l2_summary)} rows\")\n",
    "print(f\"  3. Product_Family_Summary - {len(df_family_summary)} rows\")\n",
    "print(f\"  4. BOM_Materials - {len(df_bom)} rows\")\n",
    "print(f\"  5. BOM_Summary - {len(df_bom_summary)} rows\")\n",
    "print(f\"  6. SNP_Planned_Production - {len(df_snp_filtered)} rows\")\n",
    "print(f\"  7. Procurement_Analysis - {len(df_procurement)} rows\")\n",
    "print(f\"  8. Product_Coverage - {len(df_coverage)} rows\")\n",
    "print(f\"  9. SKU_Hierarchy - {len(df_sku_mapping)} rows\\n\")\n",
    "\n",
    "print(\"OUTPUT FILE:\")\n",
    "print(f\"  üìÅ {OUTPUT_FILE}\")\n",
    "print(f\"\\n‚úì Analysis complete and ready for download!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDATA QUALITY CHECKS:\\n\")\n",
    "\n",
    "# Check 1: Missing values\n",
    "print(\"1. Missing Values in L2 Demand:\")\n",
    "missing_l2 = df_l2_demand.isnull().sum()\n",
    "if missing_l2.sum() > 0:\n",
    "    print(missing_l2[missing_l2 > 0])\n",
    "else:\n",
    "    print(\"   ‚úì No missing values\\n\")\n",
    "\n",
    "# Check 2: Data types\n",
    "print(\"2. Data Types:\")\n",
    "print(f\"   ‚úì EA values: {df_l2_demand['EA'].dtype}\")\n",
    "print(f\"   ‚úì Batches values: {df_l2_demand['Batches'].dtype}\\n\")\n",
    "\n",
    "# Check 3: Value ranges\n",
    "print(\"3. Value Ranges:\")\n",
    "print(f\"   ‚Ä¢ EA: min={df_l2_demand['EA'].min()}, max={df_l2_demand['EA'].max()}\")\n",
    "print(f\"   ‚Ä¢ Batches: min={df_l2_demand['Batches'].min()}, max={df_l2_demand['Batches'].max()}\")\n",
    "print(f\"   ‚Ä¢ Batch Size: min={df_l2_demand['Batch_Size'].min()}, max={df_l2_demand['Batch_Size'].max()}\\n\")\n",
    "\n",
    "# Check 4: Product coverage\n",
    "print(\"4. Product Coverage:\")\n",
    "for product in PRODUCTS_AVAILABLE:\n",
    "    count = len(df_l2_demand[df_l2_demand['Product_ID'] == product])\n",
    "    status = \"‚úì\" if count > 0 else \"‚ö†\"\n",
    "    print(f\"   {status} Product {product}: {count} records\")\n",
    "\n",
    "print(\"\\n‚úì Data quality checks complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
