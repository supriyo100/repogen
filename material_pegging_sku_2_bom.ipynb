{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material Pegging Map - Per-SKU Pegging with Complete Hierarchy\n",
    "## Each Market SKU sheet shows: Packing ‚Üí Assembly ‚Üí Filling hierarchy\n",
    "\n",
    "**Output:** `Material_pegging_SKU_2_BOM.xlsx`\n",
    "\n",
    "**Sheet Structure:** `Pegging_{8-series SKU}`\n",
    "\n",
    "**Hierarchy per SKU:**\n",
    "- Level 1: Market SKU (800004403) + Materials\n",
    "- Separator: 0\n",
    "- Level 2: Assembly (700003964) + Materials\n",
    "- Separator: 0\n",
    "- Level 3: Filling (700001012) + Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"MATERIAL PEGGING MAP - PER-SKU PEGGING WITH COMPLETE HIERARCHY\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "dp_file = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "snp_file = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "output_file = \"/home/supriyo/Downloads/Biocon_nw/Material_pegging_SKU_2_BOM.xlsx\"\n",
    "\n",
    "print(f\"Output: {output_file}\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== NORMALIZATION FUNCTIONS ====================\n",
    "\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return None\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text if text else None\n",
    "\n",
    "def normalize_product_no(value):\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "    text = str(value).strip()\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9]', '', text)\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "def extract_model_components(model_text):\n",
    "    if pd.isna(model_text):\n",
    "        return None\n",
    "    model_text = str(model_text).strip()\n",
    "    components = re.split(r'_+', model_text)\n",
    "    components = [c.strip() for c in components if c.strip()]\n",
    "    return '_'.join(components)\n",
    "\n",
    "def is_valid_qty(qty):\n",
    "    if pd.isna(qty):\n",
    "        return False\n",
    "    qty_str = str(qty).strip()\n",
    "    if not qty_str or qty_str == '0' or qty_str == 'nan':\n",
    "        return False\n",
    "    try:\n",
    "        return float(qty_str) > 0\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "print(\"‚úì Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== LOAD DATA ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "df_headers = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=18, nrows=4, usecols=range(14, 135))\n",
    "product_headers = {}\n",
    "for col_idx in range(df_headers.shape[1]):\n",
    "    product_id = normalize_product_no(df_headers.iloc[1, col_idx])\n",
    "    if product_id and product_id != '0':\n",
    "        product_headers[product_id] = {\n",
    "            'Product_ID': product_id,\n",
    "            'Product_Description': normalize_text(df_headers.iloc[3, col_idx]),\n",
    "            'Batch_Size': df_headers.iloc[0, col_idx],\n",
    "            'Column_Index': col_idx + 14\n",
    "        }\nprint(f\"‚úì Product headers: {len(product_headers)}\")\n",
    "\n",
    "df_materials = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=22, nrows=520, usecols=[0, 1, 2, 3, 4, 5, 10, 13])\n",
    "df_materials.columns = ['Material', 'Material_Description', 'Model', 'Product_Family', 'Section', 'Common_Unique', 'Total_Lead_Time', 'BUoM']\n",
    "df_materials['Material_Normalized'] = df_materials['Material'].apply(normalize_product_no)\n",
    "df_materials_filtered = df_materials[(df_materials['Material_Normalized'].notna()) & (df_materials['Material_Normalized'] != '0')].copy()\nprint(f\"‚úì Materials: {len(df_materials_filtered)}\")\n",
    "\n",
    "df_qty = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=22, nrows=520, usecols=range(14, 135))\n",
    "qty_col_map = {}\n",
    "for product_id, info in product_headers.items():\n",
    "    qty_col_map[product_id] = info['Column_Index'] - 14\nprint(f\"‚úì QTY data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== EXTRACT MATERIALS FOR EACH PRODUCT ====================\n",
    "\n",
    "print(\"\\nExtracting materials per product...\")\n",
    "product_materials = {}\n",
    "\n",
    "for product_id, col_idx_in_qty in qty_col_map.items():\n",
    "    qty_values = df_qty.iloc[:, col_idx_in_qty]\n",
    "    valid_qty_mask = qty_values.apply(is_valid_qty)\n",
    "    valid_row_indices = df_materials_filtered.index[valid_qty_mask[df_materials_filtered.index]].tolist()\n",
    "    \n",
    "    if len(valid_row_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    materials_for_product = df_materials_filtered.loc[valid_row_indices].copy()\n",
    "    materials_for_product['QTY'] = qty_values[valid_row_indices].values\n",
    "    materials_for_product['Product_ID'] = product_id\n",
    "    product_materials[product_id] = materials_for_product\n",
    "\nprint(f\"‚úì Extracted for {len(product_materials)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== LOAD RESOURCE & SKU DATA ====================\n",
    "\n",
    "print(\"\\nLoading Resource and SKU data...\")\n",
    "\n",
    "resource_data = {}\ntry:\n",
    "    df_resources = pd.read_excel(snp_file, sheet_name=\"DP Line Utilization\", header=None, skiprows=2, nrows=240, usecols=[1, 2, 4])\n",
    "    df_resources.columns = ['Resource_ID', 'Resource_Description', 'Product_ID']\n",
    "    for _, row in df_resources.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id:\n",
    "            resource_data[prod_id] = {\n",
    "                'Resource_ID': normalize_text(row['Resource_ID']),\n",
    "                'Resource_Description': normalize_text(row['Resource_Description'])\n",
    "            }\nexcept Exception as e:\n",
    "    print(f\"  Note: {e}\")\n\nsku_data = {}\ntry:\n",
    "    df_adv = pd.read_excel(snp_file, sheet_name=\"Adv Mkt-Mar'25\", header=None, skiprows=2, nrows=363, usecols=[1, 3, 5, 8])\n",
    "    df_adv.columns = ['Product_ID', 'SKU', 'Country', 'Pack_Size']\n",
    "    for _, row in df_adv.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id and prod_id not in sku_data:\n",
    "            sku_data[prod_id] = {'SKU': normalize_text(row['SKU']), 'Country': normalize_text(row['Country']), 'Pack_Size': row['Pack_Size']}\nexcept Exception as e:\n",
    "    pass\ntry:\n",
    "    df_em = pd.read_excel(snp_file, sheet_name=\"EM-Mar'25\", header=None, skiprows=2, nrows=44, usecols=[1, 6, 12, 14])\n",
    "    df_em.columns = ['Product_ID', 'SKU', 'Country', 'Pack_Size']\n",
    "    for _, row in df_em.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id and prod_id not in sku_data:\n",
    "            sku_data[prod_id] = {'SKU': normalize_text(row['SKU']), 'Country': normalize_text(row['Country']), 'Pack_Size': row['Pack_Size']}\nexcept Exception as e:\n",
    "    pass\nprint(f\"‚úì Resource data: {len(resource_data)}\")\nprint(f\"‚úì SKU data: {len(sku_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== DEFINE HIERARCHY ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"HIERARCHY STRUCTURE\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "hierarchy = {\n",
    "    '700001470': '700001012',  # Filling product for mCB DLP\n",
    "    '700001012': '700003964',  # Assembly product for mCB DLP\n",
    "    '700003964': [  # Market SKUs for mCB DLP\n",
    "        '800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "        '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "        '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380'\n",
    "    ],\n",
    "    '700004130': '700004129',  # Filling product for sMCB DLP\n",
    "    '700004129': [  # Market SKUs for sMCB DLP\n",
    "        '800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "        '800006524', '800006627', '800007872'\n",
    "    ],\n",
    "    '700001123': [  # Market SKUs for Vial (direct, no intermediate)\n",
    "        '800004400', '800004401', '800006626', '800006740', '800007996'\n",
    "    ],\n",
    "    '700001301': '700002770',\n",
    "    '700002770': [\n",
    "        '800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691'\n",
    "    ],\n",
    "    '700001318': [\n",
    "        '800008017', '800006529'\n",
    "    ],\n",
    "    '700000536': [\n",
    "        '800001300', '800001298', '800001299'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Mapping of Assembly -> Filling -> Root\nproduct_mapping = {\n",
    "    # mCB DLP\n",
    "    '700003964': {'assembly': '700003964', 'filling': '700001012', 'root': '700001470'},\n",
    "    # sMCB DLP\n",
    "    '800006506': {'assembly': '700004129', 'filling': '700004130', 'root': '700004130'},\n",
    "    '800006505': {'assembly': '700004129', 'filling': '700004130', 'root': '700004130'},\n",
    "    # Add mappings for other 8-series SKUs\n",
    "}\n",
    "\n",
    "# Create comprehensive mapping\nfor sku in hierarchy['700003964']:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "for sku in hierarchy['700004129']:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "for sku in hierarchy['700001123']:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "for sku in hierarchy['700002770']:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "for sku in hierarchy['700001318']:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "for sku in hierarchy['700000536']:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\nprint(f\"‚úì Hierarchy defined with {len(product_mapping)} SKU mappings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== CREATE PER-SKU PEGGING SHEETS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"CREATING PER-SKU PEGGING SHEETS\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "output_cols = ['BOM_Type', 'BOM_Level', 'Product_ID', 'Product_Description', 'SKU', 'Country', 'Pack_Size',\n",
    "               'Material', 'Material_Description', 'QTY', 'Section', 'Product_Family', 'Common_Unique',\n",
    "               'Total_Lead_Time', 'BUoM', 'Model', 'Resource_ID', 'Resource_Description', 'Batch_Size']\n",
    "\n",
    "sku_pegging_sheets = {}\n",
    "\n",
    "for market_sku, mapping_info in sorted(product_mapping.items()):\n",
    "    assembly_id = mapping_info.get('assembly')\n",
    "    filling_id = mapping_info.get('filling')\n",
    "    root_id = mapping_info.get('root')\n",
    "    family_name = mapping_info.get('family', 'Unknown')\n",
    "    \n",
    "    pegging_data = []\n",
    "    \n",
    "    # Level 1: Market SKU (Packing)\n",
    "    if market_sku in product_materials:\n",
    "        for _, mat_row in product_materials[market_sku].iterrows():\n",
    "            sku_info = sku_data.get(market_sku, {})\n",
    "            product_info = product_headers.get(market_sku, {})\n",
    "            resource_info = resource_data.get(market_sku, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Packing',\n",
    "                'BOM_Level': 'L1_Market_SKU',\n",
    "                'Product_ID': market_sku,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': sku_info.get('SKU', 'N/A'),\n",
    "                'Country': sku_info.get('Country', 'N/A'),\n",
    "                'Pack_Size': sku_info.get('Pack_Size', 'N/A'),\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    # Separator\n",
    "    pegging_data.append({col: '0' if col == 'Product_ID' else None for col in output_cols})\n",
    "    \n",
    "    # Level 2: Assembly\n",
    "    if assembly_id != market_sku and assembly_id in product_materials:\n",
    "        for _, mat_row in product_materials[assembly_id].iterrows():\n",
    "            product_info = product_headers.get(assembly_id, {})\n",
    "            resource_info = resource_data.get(assembly_id, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Assembly',\n",
    "                'BOM_Level': 'L2_Assembly',\n",
    "                'Product_ID': assembly_id,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': 'N/A',\n",
    "                'Country': 'N/A',\n",
    "                'Pack_Size': 'N/A',\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    # Separator\n",
    "    pegging_data.append({col: '0' if col == 'Product_ID' else None for col in output_cols})\n",
    "    \n",
    "    # Level 3: Filling\n",
    "    if filling_id != assembly_id and filling_id in product_materials:\n",
    "        for _, mat_row in product_materials[filling_id].iterrows():\n",
    "            product_info = product_headers.get(filling_id, {})\n",
    "            resource_info = resource_data.get(filling_id, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Filling',\n",
    "                'BOM_Level': 'L3_Filling',\n",
    "                'Product_ID': filling_id,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': 'N/A',\n",
    "                'Country': 'N/A',\n",
    "                'Pack_Size': 'N/A',\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    df_pegging = pd.DataFrame(pegging_data)[output_cols]\n",
    "    sku_pegging_sheets[market_sku] = df_pegging\n",
    "\nprint(f\"‚úì Created pegging sheets for {len(sku_pegging_sheets)} market SKUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== EXPORT TO EXCEL ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"EXPORTING TO EXCEL\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for idx, (sku, pegging_df) in enumerate(sorted(sku_pegging_sheets.items()), 1):\n",
    "        sheet_name = f\"Pegging_{sku}\"[:31]\n",
    "        pegging_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        if idx % 10 == 0 or idx == len(sku_pegging_sheets):\n",
    "            print(f\"  ‚úì Exported {idx}/{len(sku_pegging_sheets)} SKU pegging sheets...\")\n",
    "\nelapsed = time.time() - start_time\nprint(f\"\\n‚úÖ Exported: {output_file}\")\nprint(f\"   Total sheets: {len(sku_pegging_sheets)}\")\nprint(f\"‚è±Ô∏è  Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ==================== FINAL SUMMARY ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"PER-SKU PEGGING SUMMARY\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(f\"\\nüìä FILE: Material_pegging_SKU_2_BOM.xlsx\")\n",
    "print(f\"\\nüìã SHEETS:\")\n",
    "print(f\"  Total SKU Pegging Sheets: {len(sku_pegging_sheets)}\")\n",
    "\n",
    "print(f\"\\nüìä SHEET STRUCTURE (Per Market SKU):\")\n",
    "print(f\"  Level 1 (Packing): Market SKU materials\")\n",
    "print(f\"  Separator: 0 (Product_ID column only)\")\n",
    "print(f\"  Level 2 (Assembly): Assembly materials\")\n",
    "print(f\"  Separator: 0 (Product_ID column only)\")\n",
    "print(f\"  Level 3 (Filling): Filling materials\")\n",
    "\n",
    "print(f\"\\nüìã COLUMNS (19):\")\nfor idx, col in enumerate(output_cols, 1):\n",
    "    print(f\"  {idx:2d}. {col}\")\n",
    "\nprint(f\"\\n‚úÖ Each market SKU has complete hierarchical BOM!\")\nprint(f\"‚úÖ All columns include: Product info, Materials, Resources, Lead Times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.8.0"\n",
  }\n",
 },\n",
 "nbformat": 4,\n",
 "nbformat_minor": 4\n}
