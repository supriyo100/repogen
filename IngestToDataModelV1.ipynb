{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1340751e-5ab4-4efb-9e16-40551a2c2ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\nMATERIAL PEGGING MAP - PER-SKU PEGGING WITH COMPLETE HIERARCHY\n========================================================================================================================\ndp_file: /dbfs/FileStore/tables/20251006_DP_Material_Shortage___Working_file.xlsx\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ZipFile.__del__ at 0x7f2d9b4bcd30>\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/zipfile.py\", line 1834, in __del__\n    self.close()\n  File \"/usr/lib/python3.10/zipfile.py\", line 1851, in close\n    self.fp.seek(self.start_dir)\nValueError: seek of closed file\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Date: 01/06/2020     Unnamed: 1  ... Unnamed: 39 Unnamed: 40\n0              NaN  Insugen 30/70  ...         NaN         NaN\n1              May              0  ...         NaN         NaN\n2             June              2  ...         NaN         NaN\n3             July              3  ...         NaN         NaN\n4           August              3  ...         NaN         NaN\n\n[5 rows x 41 columns]\n['20251006_DP_Material_Shortage___Working_file.xlsx', 'Aug_25_L2_DP_Plan_Circulation_V2.xlsx', 'Material_pegging_SKU_2_BOM.xlsx', 'ParkourSC_SNP.xlsx', 'my_dataframe.csv', 'output', 'test']\n"
     ]
    }
   ],
   "source": [
    "# Importing Files and Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "import warnings\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"MATERIAL PEGGING MAP - PER-SKU PEGGING WITH COMPLETE HIERARCHY\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "dp_file = \"/dbfs/FileStore/tables/20251006_DP_Material_Shortage___Working_file.xlsx\"\n",
    "snp_file = \"/dbfs/FileStore/tables/ParkourSC_SNP.xlsx\"\n",
    "pegging_file = \"/dbfs/FileStore/tables/Material_pegging_SKU_2_BOM.xlsx\"\n",
    "\n",
    "output_dir = \"/dbfs/FileStore/tables/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"dp_file: {dp_file}\")\n",
    "\n",
    "if os.path.exists(dp_file):\n",
    "    df_dp = pd.read_excel(dp_file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"The file {dp_file} does not exist.\")\n",
    "\n",
    "print(df_dp.head())\n",
    "\n",
    "\n",
    "# Check names of the Files\n",
    "import os\n",
    "print(os.listdir(\"/dbfs/FileStore/tables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6f1ed0a5-8804-4754-a288-6690b1364a20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/20251006_DP_Material_Shortage___Working_file.xlsx</td><td>20251006_DP_Material_Shortage___Working_file.xlsx</td><td>26368580</td><td>1764843045000</td></tr><tr><td>dbfs:/FileStore/tables/Aug_25_L2_DP_Plan_Circulation_V2.xlsx</td><td>Aug_25_L2_DP_Plan_Circulation_V2.xlsx</td><td>176999</td><td>1764843036000</td></tr><tr><td>dbfs:/FileStore/tables/Material_pegging_SKU_2_BOM.xlsx</td><td>Material_pegging_SKU_2_BOM.xlsx</td><td>241208</td><td>1764843075000</td></tr><tr><td>dbfs:/FileStore/tables/ParkourSC_SNP.xlsx</td><td>ParkourSC_SNP.xlsx</td><td>623641</td><td>1764843047000</td></tr><tr><td>dbfs:/FileStore/tables/my_dataframe.csv</td><td>my_dataframe.csv</td><td>307320</td><td>1702349271000</td></tr><tr><td>dbfs:/FileStore/tables/output/</td><td>output/</td><td>0</td><td>1765174072053</td></tr><tr><td>dbfs:/FileStore/tables/test/</td><td>test/</td><td>0</td><td>1765174072053</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/20251006_DP_Material_Shortage___Working_file.xlsx",
         "20251006_DP_Material_Shortage___Working_file.xlsx",
         26368580,
         1764843045000
        ],
        [
         "dbfs:/FileStore/tables/Aug_25_L2_DP_Plan_Circulation_V2.xlsx",
         "Aug_25_L2_DP_Plan_Circulation_V2.xlsx",
         176999,
         1764843036000
        ],
        [
         "dbfs:/FileStore/tables/Material_pegging_SKU_2_BOM.xlsx",
         "Material_pegging_SKU_2_BOM.xlsx",
         241208,
         1764843075000
        ],
        [
         "dbfs:/FileStore/tables/ParkourSC_SNP.xlsx",
         "ParkourSC_SNP.xlsx",
         623641,
         1764843047000
        ],
        [
         "dbfs:/FileStore/tables/my_dataframe.csv",
         "my_dataframe.csv",
         307320,
         1702349271000
        ],
        [
         "dbfs:/FileStore/tables/output/",
         "output/",
         0,
         1765174072053
        ],
        [
         "dbfs:/FileStore/tables/test/",
         "test/",
         0,
         1765174072053
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Display Files stored in DBFS\n",
    "display(dbutils.fs.ls(\"/FileStore/tables\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a79406c7-9490-4131-9aa0-7afcb63350bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Normalize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "eff7b4e2-e7da-4268-87d0-b91ad4fa1491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Nomalize Text\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return None\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'\\\\s+', ' ', text)\n",
    "    return text if text else None\n",
    "\n",
    "def normalize_product_no(value):\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "    text = str(value).strip()\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9]', '', text)\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "def extract_model_components(model_text):\n",
    "    if pd.isna(model_text):\n",
    "        return None\n",
    "    model_text = str(model_text).strip()\n",
    "    components = re.split(r'_+', model_text)\n",
    "    components = [c.strip() for c in components if c.strip()]\n",
    "    return '_'.join(components)\n",
    "\n",
    "def is_valid_qty(qty):\n",
    "    if pd.isna(qty):\n",
    "        return False\n",
    "    qty_str = str(qty).strip()\n",
    "    if not qty_str or qty_str == '0' or qty_str == 'nan':\n",
    "        return False\n",
    "    try:\n",
    "        return float(qty_str) > 0\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d50c182-25a7-49cf-84c1-6a38c6eacbfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Loading Data into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3fc704a3-e816-4301-b407-f636a5328a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product headers: 87\nMaterials: 520\nData loaded successfully\n"
     ]
    }
   ],
   "source": [
    "## Loading Data into DataFrames\n",
    "print(\"Loading data...\")\n",
    "\n",
    "df_headers = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=18, nrows=4, usecols=range(14, 135))\n",
    "product_headers = {}\n",
    "for col_idx in range(df_headers.shape[1]):\n",
    "    product_id = normalize_product_no(df_headers.iloc[1, col_idx])\n",
    "    if product_id and product_id != '0':\n",
    "        product_headers[product_id] = {\n",
    "            'Product_ID': product_id,\n",
    "            'Product_Description': normalize_text(df_headers.iloc[3, col_idx]),\n",
    "            'Batch_Size': df_headers.iloc[0, col_idx],\n",
    "            'Column_Index': col_idx + 14\n",
    "        }\n",
    "\n",
    "print(f\"Product headers: {len(product_headers)}\")\n",
    "\n",
    "df_materials = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=22, nrows=520, usecols=[0, 1, 2, 3, 4, 5, 10, 13])\n",
    "df_materials.columns = ['Material', 'Material_Description', 'Model', 'Product_Family', 'Section', 'Common_Unique', 'Total_Lead_Time', 'BUoM']\n",
    "df_materials['Material_Normalized'] = df_materials['Material'].apply(normalize_product_no)\n",
    "df_materials_filtered = df_materials[(df_materials['Material_Normalized'].notna()) & (df_materials['Material_Normalized'] != '0')].copy()\n",
    "print(f\"Materials: {len(df_materials_filtered)}\")\n",
    "\n",
    "df_qty = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=22, nrows=520, usecols=range(14, 135))\n",
    "qty_col_map = {}\n",
    "for product_id, info in product_headers.items():\n",
    "    qty_col_map[product_id] = info['Column_Index'] - 14\n",
    "\n",
    "print(\"Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0854a4bc-65a0-4b67-856f-124f10384d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extracting materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3ad0d11a-110e-49d7-bf19-c42541c95ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting materials per product...\nExtracted for 87 products\n"
     ]
    }
   ],
   "source": [
    "## Extracting materials\n",
    "print(\"Extracting materials per product...\")\n",
    "product_materials = {}\n",
    "\n",
    "for product_id, col_idx_in_qty in qty_col_map.items():\n",
    "    qty_values = df_qty.iloc[:, col_idx_in_qty]\n",
    "    valid_qty_mask = qty_values.apply(is_valid_qty)\n",
    "    valid_row_indices = df_materials_filtered.index[valid_qty_mask[df_materials_filtered.index]].tolist()\n",
    "    \n",
    "    if len(valid_row_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    materials_for_product = df_materials_filtered.loc[valid_row_indices].copy()\n",
    "    materials_for_product['QTY'] = qty_values[valid_row_indices].values\n",
    "    materials_for_product['Product_ID'] = product_id\n",
    "    product_materials[product_id] = materials_for_product\n",
    "\n",
    "print(f\"Extracted for {len(product_materials)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d065f599-5a44-4105-9cc0-a1410ef0696f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Loading Resources and SKU's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6d266e5b-a9b1-49c2-b97e-398c45f0cec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Resource and SKU data...\nResource data: 64\nSKU data: 76\n"
     ]
    }
   ],
   "source": [
    "## Loading Resources and SKU's\n",
    "print(\"Loading Resource and SKU data...\")\n",
    "\n",
    "resource_data = {}\n",
    "try:\n",
    "    df_resources = pd.read_excel(snp_file, sheet_name=\"DP Line Utilization\", header=None, skiprows=2, nrows=240, usecols=[1, 2, 4])\n",
    "    df_resources.columns = ['Resource_ID', 'Resource_Description', 'Product_ID']\n",
    "    for _, row in df_resources.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id:\n",
    "            resource_data[prod_id] = {\n",
    "                'Resource_ID': normalize_text(row['Resource_ID']),\n",
    "                'Resource_Description': normalize_text(row['Resource_Description'])\n",
    "            }\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "\n",
    "sku_data = {}\n",
    "try:\n",
    "    df_adv = pd.read_excel(snp_file, sheet_name=\"Adv Mkt-Mar'25\", header=None, skiprows=2, nrows=363, usecols=[1, 3, 5, 8])\n",
    "    df_adv.columns = ['Product_ID', 'SKU', 'Country', 'Pack_Size']\n",
    "    for _, row in df_adv.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id and prod_id not in sku_data:\n",
    "            sku_data[prod_id] = {'SKU': normalize_text(row['SKU']), 'Country': normalize_text(row['Country']), 'Pack_Size': row['Pack_Size']}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df_em = pd.read_excel(snp_file, sheet_name=\"EM-Mar'25\", header=None, skiprows=2, nrows=44, usecols=[1, 6, 12, 14])\n",
    "    df_em.columns = ['Product_ID', 'SKU', 'Country', 'Pack_Size']\n",
    "    for _, row in df_em.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id and prod_id not in sku_data:\n",
    "            sku_data[prod_id] = {'SKU': normalize_text(row['SKU']), 'Country': normalize_text(row['Country']), 'Pack_Size': row['Pack_Size']}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(f\"Resource data: {len(resource_data)}\")\n",
    "print(f\"SKU data: {len(sku_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "192ca3aa-f1c3-4f11-958f-552ab9f45bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining hierarchy...\nHierarchy defined with 52 SKU mappings\n"
     ]
    }
   ],
   "source": [
    "# SKU hierarchy\n",
    "print(\"Defining hierarchy...\")\n",
    "\n",
    "product_mapping = {}\n",
    "\n",
    "mCB_skus = ['800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "            '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "            '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380']\n",
    "\n",
    "sMCB_skus = ['800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "             '800006524', '800006627', '800007872']\n",
    "\n",
    "vial_skus = ['800004400', '800004401', '800006626', '800006740', '800007996']\n",
    "\n",
    "aspart_dlp_skus = ['800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691']\n",
    "\n",
    "aspart_vial_skus = ['800008017', '800006529']\n",
    "\n",
    "rhi_skus = ['800001300', '800001298', '800001299']\n",
    "\n",
    "for sku in mCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "\n",
    "for sku in sMCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "\n",
    "for sku in vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "\n",
    "for sku in aspart_dlp_skus:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "\n",
    "for sku in aspart_vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "\n",
    "for sku in rhi_skus:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\n",
    "print(f\"Hierarchy defined with {len(product_mapping)} SKU mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14255f92-abb6-4505-bf88-fc024d35ed50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating per-SKU pegging sheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fdbb1db0-4c07-4b5a-82d9-5a5e4fd618fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating per-SKU pegging sheets...\nCreated pegging sheets for 52 market SKUs\n"
     ]
    }
   ],
   "source": [
    "# Creating per-SKU pegging sheets\n",
    "print(\"Creating per-SKU pegging sheets...\")\n",
    "\n",
    "output_cols = ['BOM_Type', 'BOM_Level', 'Product_ID', 'Product_Description', 'SKU', 'Country', 'Pack_Size',\n",
    "               'Material', 'Material_Description', 'QTY', 'Section', 'Product_Family', 'Common_Unique',\n",
    "               'Total_Lead_Time', 'BUoM', 'Model', 'Resource_ID', 'Resource_Description', 'Batch_Size']\n",
    "\n",
    "sku_pegging_sheets = {}\n",
    "\n",
    "for market_sku, mapping_info in sorted(product_mapping.items()):\n",
    "    assembly_id = mapping_info.get('assembly')\n",
    "    filling_id = mapping_info.get('filling')\n",
    "    family_name = mapping_info.get('family', 'Unknown')\n",
    "    \n",
    "    pegging_data = []\n",
    "    \n",
    "    if market_sku in product_materials:\n",
    "        for _, mat_row in product_materials[market_sku].iterrows():\n",
    "            sku_info = sku_data.get(market_sku, {})\n",
    "            product_info = product_headers.get(market_sku, {})\n",
    "            resource_info = resource_data.get(market_sku, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Packing',\n",
    "                'BOM_Level': 'L1_Market_SKU',\n",
    "                'Product_ID': market_sku,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': sku_info.get('SKU', 'N/A'),\n",
    "                'Country': sku_info.get('Country', 'N/A'),\n",
    "                'Pack_Size': sku_info.get('Pack_Size', 'N/A'),\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    pegging_data.append({col: '0' if col == 'Product_ID' else None for col in output_cols})\n",
    "    \n",
    "    if assembly_id != market_sku and assembly_id in product_materials:\n",
    "        for _, mat_row in product_materials[assembly_id].iterrows():\n",
    "            product_info = product_headers.get(assembly_id, {})\n",
    "            resource_info = resource_data.get(assembly_id, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Assembly',\n",
    "                'BOM_Level': 'L2_Assembly',\n",
    "                'Product_ID': assembly_id,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': 'N/A',\n",
    "                'Country': 'N/A',\n",
    "                'Pack_Size': 'N/A',\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    pegging_data.append({col: '0' if col == 'Product_ID' else None for col in output_cols})\n",
    "    \n",
    "    if filling_id != assembly_id and filling_id in product_materials:\n",
    "        for _, mat_row in product_materials[filling_id].iterrows():\n",
    "            product_info = product_headers.get(filling_id, {})\n",
    "            resource_info = resource_data.get(filling_id, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Filling',\n",
    "                'BOM_Level': 'L3_Filling',\n",
    "                'Product_ID': filling_id,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': 'N/A',\n",
    "                'Country': 'N/A',\n",
    "                'Pack_Size': 'N/A',\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    df_pegging = pd.DataFrame(pegging_data)[output_cols]\n",
    "    sku_pegging_sheets[market_sku] = df_pegging\n",
    "\n",
    "print(f\"Created pegging sheets for {len(sku_pegging_sheets)} market SKUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d362ed86-5b5d-4032-8cd9-719a0e13f41d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exporting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3adaf4-4b83-4b9f-b352-ce0bff30f66b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Exported 10/52 SKU pegging sheets\n  Exported 20/52 SKU pegging sheets\n  Exported 30/52 SKU pegging sheets\n  Exported 40/52 SKU pegging sheets\n  Exported 50/52 SKU pegging sheets\n  Exported 52/52 SKU pegging sheets\n\nExported CSVs to: /dbfs/FileStore/tables/output\nTotal sheets: 52\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save each SKU pegging sheet as CSV to DBFS\n",
    "dbfs_output_dir = \"/dbfs/FileStore/tables/output\"\n",
    "os.makedirs(dbfs_output_dir, exist_ok=True)\n",
    "\n",
    "for idx, (sku, pegging_df) in enumerate(sorted(sku_pegging_sheets.items()), 1):\n",
    "    csv_path = os.path.join(dbfs_output_dir, f\"Pegging_{sku}.csv\")\n",
    "    pegging_df.to_csv(csv_path, index=False)\n",
    "    if idx % 10 == 0 or idx == len(sku_pegging_sheets):\n",
    "        print(f\"  Exported {idx}/{len(sku_pegging_sheets)} SKU pegging sheets\")\n",
    "\n",
    "print(f\"\\nExported CSVs to: {dbfs_output_dir}\")\n",
    "print(f\"Total sheets: {len(sku_pegging_sheets)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "IngestToDataModelV1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}