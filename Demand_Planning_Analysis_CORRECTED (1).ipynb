{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biocon DP Demand Planning & BOM Analysis\n",
    "## Multi-File Integration: Demand Mapping & Procurement Analysis\n",
    "\n",
    "**Purpose:** Extract L2 demand, map to BOM, calculate procurement needs\n",
    "\n",
    "**Files Used:**\n",
    "1. Aug'25_L2_DP_Plan_Circulation_V2.xlsx - L2 demand plan\n",
    "2. ParkourSC_SNP.xlsx - Supply chain planned production\n",
    "3. 20251006-DP Material Shortage - Working file.xlsx - BOM/Materials\n",
    "\n",
    "**Output:** Excel file with 9 sheets of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure File Paths & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths - UPDATE THESE IF FILES ARE IN DIFFERENT LOCATIONS\n",
    "AUG25_FILE = \"/home/supriyo/Downloads/Biocon_nw/Aug'25_L2_DP_Plan_Circulation_V2.xlsx\"\n",
    "SNP_FILE = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "BOM_FILE = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "OUTPUT_FILE = \"/mnt/user-data/outputs/Demand_Planning_Analysis.xlsx\"\n",
    "\n",
    "# Sheet Names\n",
    "AUG25_SHEET = \"L2Ph1_Detail\"\n",
    "SNP_SHEET = \"DP RCCP\"\n",
    "BOM_SHEET = \"DP Shortage\"\n",
    "\n",
    "# Products Configuration\n",
    "PRODUCTS_AVAILABLE = [700001012, 700001123, 700000536, 700001318, 700001301]\n",
    "PRODUCTS_NOT_AVAILABLE = [700004130]\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")\n",
    "print(f\"  Input files: 3\")\n",
    "print(f\"  Output file: {OUTPUT_FILE}\")\n",
    "print(f\"  Products to analyze: {len(PRODUCTS_AVAILABLE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Product Hierarchy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all SKU mappings with product hierarchy\n",
    "mCB_skus = ['800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "            '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "            '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380']\n",
    "\n",
    "sMCB_skus = ['800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "             '800006524', '800006627', '800007872']\n",
    "\n",
    "vial_skus = ['800004400', '800004401', '800006626', '800006740', '800007996']\n",
    "\n",
    "aspart_dlp_skus = ['800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691']\n",
    "\n",
    "aspart_vial_skus = ['800008017', '800006529']\n",
    "\n",
    "rhi_skus = ['800001300', '800001298', '800001299']\n",
    "\n",
    "# Build product mapping\n",
    "product_mapping = {}\n",
    "\n",
    "for sku in mCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "\n",
    "for sku in sMCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "\n",
    "for sku in vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "\n",
    "for sku in aspart_dlp_skus:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "\n",
    "for sku in aspart_vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "\n",
    "for sku in rhi_skus:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\n",
    "print(f\"âœ“ Product hierarchy defined with {len(product_mapping)} SKU mappings\")\n",
    "print(f\"  - mCB: {len(mCB_skus)} SKUs â†’ 700001012\")\n",
    "print(f\"  - sMCB: {len(sMCB_skus)} SKUs â†’ 700004130 (NOT AVAILABLE)\")\n",
    "print(f\"  - Vial: {len(vial_skus)} SKUs â†’ 700001123\")\n",
    "print(f\"  - Aspart DLP: {len(aspart_dlp_skus)} SKUs â†’ 700001301\")\n",
    "print(f\"  - Aspart Vial: {len(aspart_vial_skus)} SKUs â†’ 700001318\")\n",
    "print(f\"  - RHI: {len(rhi_skus)} SKUs â†’ 700000536\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_month(header_str):\n",
    "    \"\"\"Convert month header to standardized format (MM.YYYY)\"\"\"\n",
    "    month_map = {\n",
    "        'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "        'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "    }\n",
    "    \n",
    "    header_str = str(header_str).upper().strip()\n",
    "    \n",
    "    for month_str, month_num in month_map.items():\n",
    "        if month_str in header_str:\n",
    "            year_match = re.search(r'202\\d', header_str)\n",
    "            if year_match:\n",
    "                year = year_match.group()\n",
    "                return f\"{month_num:02d}.{year}\"\n",
    "    \n",
    "    return header_str\n",
    "\n",
    "print(\"âœ“ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract L2 Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Aug25 L2 demand data...\\n\")\n",
    "\n",
    "try:\n",
    "    wb_aug25 = openpyxl.load_workbook(AUG25_FILE)\n",
    "    ws_aug25 = wb_aug25[AUG25_SHEET]\n",
    "    \n",
    "    # Get month headers from columns S to AM (columns 19-39)\n",
    "    month_headers = []\n",
    "    for col_idx in range(19, 40):\n",
    "        header = ws_aug25.cell(row=2, column=col_idx).value\n",
    "        if header:\n",
    "            month_headers.append(normalize_month(header))\n",
    "    \n",
    "    print(f\"âœ“ Found {len(month_headers)} month headers\")\n",
    "    print(f\"  Months: {month_headers[:3]} to {month_headers[-2:]}\")\n",
    "    \n",
    "    # Extract demand data\n",
    "    l2_demand_data = []\n",
    "    \n",
    "    for row_idx in range(3, 79):  # Row 3 to 78\n",
    "        market_sku = ws_aug25.cell(row=row_idx, column=5).value  # Col E\n",
    "        batch_size = ws_aug25.cell(row=row_idx, column=11).value  # Col K\n",
    "        \n",
    "        if market_sku and str(market_sku).strip() != '':\n",
    "            market_sku = str(market_sku).strip()\n",
    "            batch_size = float(batch_size) if batch_size else 0\n",
    "            \n",
    "            product_info = product_mapping.get(market_sku, {})\n",
    "            \n",
    "            # Extract monthly demand\n",
    "            for col_idx, month in enumerate(month_headers):\n",
    "                ea_col = 19 + col_idx  # Column S onwards\n",
    "                batch_col = 40 + col_idx  # Column AN onwards\n",
    "                \n",
    "                ea_value = ws_aug25.cell(row=row_idx, column=ea_col).value\n",
    "                batch_value = ws_aug25.cell(row=row_idx, column=batch_col).value\n",
    "                \n",
    "                ea_value = float(ea_value) if ea_value and str(ea_value).strip() != '' else 0\n",
    "                batch_value = float(batch_value) if batch_value and str(batch_value).strip() != '' else 0\n",
    "                \n",
    "                l2_demand_data.append({\n",
    "                    'Market_SKU': market_sku,\n",
    "                    'Product_ID': product_info.get('filling', 'N/A'),\n",
    "                    'Product_Family': product_info.get('family', 'Unknown'),\n",
    "                    'Batch_Size': batch_size,\n",
    "                    'Month': month,\n",
    "                    'EA': ea_value,\n",
    "                    'Batches': batch_value\n",
    "                })\n",
    "    \n",
    "    df_l2_demand = pd.DataFrame(l2_demand_data)\n",
    "    \n",
    "    print(f\"\\nâœ“ Extracted L2 demand data\")\n",
    "    print(f\"  Total records: {len(df_l2_demand)}\")\n",
    "    print(f\"  Unique SKUs: {df_l2_demand['Market_SKU'].nunique()}\")\n",
    "    print(f\"  Unique Products: {df_l2_demand['Product_ID'].nunique()}\")\n",
    "    print(f\"  Date range: {df_l2_demand['Month'].min()} to {df_l2_demand['Month'].max()}\")\n",
    "    \n",
    "    print(\"\\nSample L2 Demand Data:\")\n",
    "    print(df_l2_demand.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract SNP Planned Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading SNP planned production data...\\n\")\n",
    "\n",
    "try:\n",
    "    df_snp = pd.read_excel(SNP_FILE, sheet_name=SNP_SHEET)\n",
    "    \n",
    "    print(f\"âœ“ SNP data loaded\")\n",
    "    print(f\"  Shape: {df_snp.shape}\")\n",
    "    print(f\"  Columns: {list(df_snp.columns)}\\n\")\n",
    "    \n",
    "    # Filter for Planned Production\n",
    "    df_snp_planned = df_snp[df_snp['Key Figure'] == 'Planned Production'].copy()\n",
    "    print(f\"âœ“ Filtered for 'Planned Production': {len(df_snp_planned)} records\")\n",
    "    \n",
    "    # Convert Product ID to numeric\n",
    "    product_col = [col for col in df_snp_planned.columns if 'Product' in col][0]\n",
    "    df_snp_planned['Product_ID'] = pd.to_numeric(df_snp_planned[product_col], errors='coerce')\n",
    "    \n",
    "    # Filter for available products\n",
    "    df_snp_filtered = df_snp_planned[df_snp_planned['Product_ID'].isin(PRODUCTS_AVAILABLE)].copy()\n",
    "    \n",
    "    print(f\"âœ“ Filtered for available products: {len(df_snp_filtered)} records\\n\")\n",
    "    print(\"Sample SNP Data:\")\n",
    "    print(df_snp_filtered.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extract BOM Material Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading BOM material data...\\n\")\n",
    "\n",
    "try:\n",
    "    wb_bom = openpyxl.load_workbook(BOM_FILE)\n",
    "    ws_bom = wb_bom[BOM_SHEET]\n",
    "    \n",
    "    bom_data = []\n",
    "    \n",
    "    for row_idx in range(23, 543):  # Row 23 to 542\n",
    "        material_id = ws_bom.cell(row=row_idx, column=1).value  # Col A\n",
    "        material_desc = ws_bom.cell(row=row_idx, column=2).value  # Col B\n",
    "        model = ws_bom.cell(row=row_idx, column=3).value  # Col C\n",
    "        product_family = ws_bom.cell(row=row_idx, column=4).value  # Col D\n",
    "        section = ws_bom.cell(row=row_idx, column=5).value  # Col E\n",
    "        component_id = ws_bom.cell(row=row_idx, column=6).value  # Col F\n",
    "        \n",
    "        # Filter: skip blank and 0 values\n",
    "        if material_id is None or str(material_id).strip() == '' or material_id == 0:\n",
    "            continue\n",
    "        \n",
    "        bom_data.append({\n",
    "            'Material_ID': material_id,\n",
    "            'Material_Description': material_desc,\n",
    "            'Model': model,\n",
    "            'Product_Family': product_family,\n",
    "            'Section': section,\n",
    "            'Component_ID': component_id\n",
    "        })\n",
    "    \n",
    "    df_bom = pd.DataFrame(bom_data)\n",
    "    \n",
    "    print(f\"âœ“ Extracted BOM data\")\n",
    "    print(f\"  Total materials: {len(df_bom)}\")\n",
    "    print(f\"  Unique product families: {df_bom['Product_Family'].nunique()}\\n\")\n",
    "    \n",
    "    print(\"Sample BOM Data:\")\n",
    "    print(df_bom.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Summary Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating summary sheets...\\n\")\n",
    "\n",
    "# 1. L2 Demand Summary (by Month and Product)\n",
    "df_l2_summary = df_l2_demand.groupby(['Month', 'Product_ID', 'Product_Family']).agg({\n",
    "    'EA': 'sum',\n",
    "    'Batches': 'sum',\n",
    "    'Market_SKU': 'count'\n",
    "}).rename(columns={'Market_SKU': 'SKU_Count'}).reset_index()\n",
    "\n",
    "print(f\"âœ“ L2 Demand Summary: {len(df_l2_summary)} records\")\n",
    "\n",
    "# 2. Product Family Summary\n",
    "df_family_summary = df_l2_demand.groupby('Product_Family').agg({\n",
    "    'EA': 'sum',\n",
    "    'Batches': 'sum',\n",
    "    'Market_SKU': 'nunique',\n",
    "    'Product_ID': 'nunique'\n",
    "}).rename(columns={\n",
    "    'EA': 'Total_EA',\n",
    "    'Batches': 'Total_Batches',\n",
    "    'Market_SKU': 'Unique_SKUs',\n",
    "    'Product_ID': 'Unique_Products'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"âœ“ Product Family Summary: {len(df_family_summary)} families\")\n",
    "\n",
    "# 3. BOM Summary by Product Family\n",
    "df_bom_summary = df_bom.groupby('Product_Family').agg({\n",
    "    'Material_ID': 'count',\n",
    "    'Component_ID': 'nunique'\n",
    "}).rename(columns={\n",
    "    'Material_ID': 'Total_Materials',\n",
    "    'Component_ID': 'Unique_Components'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"âœ“ BOM Summary: {len(df_bom_summary)} families\")\n",
    "\n",
    "# 4. Procurement Analysis\n",
    "procurement_data = []\n",
    "for _, row in df_snp_filtered.iterrows():\n",
    "    procurement_data.append({\n",
    "        'Product_ID': row.get('Product_ID', 'N/A'),\n",
    "        'Total_Demand': 0,\n",
    "        'Unrestricted_Stock': 0,\n",
    "        'OPO': 0,\n",
    "        'OS_PR': 0,\n",
    "        'Safety_Stock': 0\n",
    "    })\n",
    "\n",
    "df_procurement = pd.DataFrame(procurement_data)\n",
    "df_procurement['Procurement_Upper_Bound'] = (\n",
    "    df_procurement['Total_Demand']\n",
    "    - (\n",
    "        df_procurement['Unrestricted_Stock']\n",
    "        + df_procurement['OPO']\n",
    "        + df_procurement['OS_PR']\n",
    "        - df_procurement['Safety_Stock']\n",
    "    )\n",
    ").clip(lower=0)\n",
    "\n",
    "print(f\"âœ“ Procurement Analysis: {len(df_procurement)} products\")\n",
    "\n",
    "# 5. Product Coverage\n",
    "products_in_demand = set(df_l2_demand['Product_ID'].unique())\n",
    "products_in_snp = set(df_snp_filtered['Product_ID'].unique())\n",
    "products_coverage = products_in_demand.union(products_in_snp)\n",
    "\n",
    "df_coverage = pd.DataFrame({\n",
    "    'Product_ID': list(products_coverage),\n",
    "    'In_L2_Demand': [pid in products_in_demand for pid in products_coverage],\n",
    "    'In_SNP_Plan': [pid in products_in_snp for pid in products_coverage]\n",
    "})\n",
    "\n",
    "print(f\"âœ“ Product Coverage: {len(df_coverage)} products\\n\")\n",
    "\n",
    "print(\"Summary creation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create SKU Mapping DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SKU Hierarchy DataFrame\n",
    "df_sku_mapping = pd.DataFrame([\n",
    "    {'SKU': sku, **info} for sku, info in product_mapping.items()\n",
    "])\n",
    "\n",
    "print(f\"âœ“ SKU Hierarchy mapping: {len(df_sku_mapping)} SKUs\")\n",
    "print(\"\\nSample SKU Hierarchy:\")\n",
    "print(df_sku_mapping.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Write All Sheets to Excel Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Excel output file...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create Excel writer\n",
    "    with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:\n",
    "        # Sheet 1: L2 Demand Detail\n",
    "        df_l2_demand.to_excel(writer, sheet_name='L2_Demand_Detail', index=False)\n",
    "        print(\"âœ“ Sheet 1: L2_Demand_Detail\")\n",
    "        \n",
    "        # Sheet 2: L2 Demand Summary\n",
    "        df_l2_summary.to_excel(writer, sheet_name='L2_Demand_Summary', index=False)\n",
    "        print(\"âœ“ Sheet 2: L2_Demand_Summary\")\n",
    "        \n",
    "        # Sheet 3: Product Family Summary\n",
    "        df_family_summary.to_excel(writer, sheet_name='Product_Family_Summary', index=False)\n",
    "        print(\"âœ“ Sheet 3: Product_Family_Summary\")\n",
    "        \n",
    "        # Sheet 4: BOM Materials\n",
    "        df_bom.to_excel(writer, sheet_name='BOM_Materials', index=False)\n",
    "        print(\"âœ“ Sheet 4: BOM_Materials\")\n",
    "        \n",
    "        # Sheet 5: BOM Summary\n",
    "        df_bom_summary.to_excel(writer, sheet_name='BOM_Summary', index=False)\n",
    "        print(\"âœ“ Sheet 5: BOM_Summary\")\n",
    "        \n",
    "        # Sheet 6: SNP Planned Production\n",
    "        df_snp_filtered.to_excel(writer, sheet_name='SNP_Planned_Production', index=False)\n",
    "        print(\"âœ“ Sheet 6: SNP_Planned_Production\")\n",
    "        \n",
    "        # Sheet 7: Procurement Analysis\n",
    "        df_procurement.to_excel(writer, sheet_name='Procurement_Analysis', index=False)\n",
    "        print(\"âœ“ Sheet 7: Procurement_Analysis\")\n",
    "        \n",
    "        # Sheet 8: Product Coverage\n",
    "        df_coverage.to_excel(writer, sheet_name='Product_Coverage', index=False)\n",
    "        print(\"âœ“ Sheet 8: Product_Coverage\")\n",
    "        \n",
    "        # Sheet 9: SKU Hierarchy\n",
    "        df_sku_mapping.to_excel(writer, sheet_name='SKU_Hierarchy', index=False)\n",
    "        print(\"âœ“ Sheet 9: SKU_Hierarchy\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"âœ“ Excel file created successfully!\")\n",
    "    print(f\"âœ“ Location: {OUTPUT_FILE}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Summary & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"INPUT FILES:\")\n",
    "print(f\"  1. Aug'25 L2 Demand Plan: {df_l2_demand['Market_SKU'].nunique()} unique SKUs\")\n",
    "print(f\"  2. SNP Planned Production: {len(df_snp_filtered)} records\")\n",
    "print(f\"  3. BOM Materials: {len(df_bom)} materials\\n\")\n",
    "\n",
    "print(\"DATA EXTRACTED:\")\n",
    "print(f\"  â€¢ L2 Demand Records: {len(df_l2_demand)}\")\n",
    "print(f\"  â€¢ Unique Products: {df_l2_demand['Product_ID'].nunique()}\")\n",
    "print(f\"  â€¢ Unique Families: {df_l2_demand['Product_Family'].nunique()}\")\n",
    "print(f\"  â€¢ Date Range: {df_l2_demand['Month'].min()} to {df_l2_demand['Month'].max()}\\n\")\n",
    "\n",
    "print(\"PRODUCT HIERARCHY:\")\n",
    "print(f\"  â€¢ Total SKUs Mapped: {len(product_mapping)}\")\n",
    "print(f\"  â€¢ Available Products: {len(PRODUCTS_AVAILABLE)}\")\n",
    "print(f\"  â€¢ Unavailable Products: {len(PRODUCTS_NOT_AVAILABLE)}\\n\")\n",
    "\n",
    "print(\"OUTPUT EXCEL SHEETS (9 total):\")\n",
    "print(f\"  1. L2_Demand_Detail - {len(df_l2_demand)} rows\")\n",
    "print(f\"  2. L2_Demand_Summary - {len(df_l2_summary)} rows\")\n",
    "print(f\"  3. Product_Family_Summary - {len(df_family_summary)} rows\")\n",
    "print(f\"  4. BOM_Materials - {len(df_bom)} rows\")\n",
    "print(f\"  5. BOM_Summary - {len(df_bom_summary)} rows\")\n",
    "print(f\"  6. SNP_Planned_Production - {len(df_snp_filtered)} rows\")\n",
    "print(f\"  7. Procurement_Analysis - {len(df_procurement)} rows\")\n",
    "print(f\"  8. Product_Coverage - {len(df_coverage)} rows\")\n",
    "print(f\"  9. SKU_Hierarchy - {len(df_sku_mapping)} rows\\n\")\n",
    "\n",
    "print(\"OUTPUT FILE:\")\n",
    "print(f\"  ðŸ“ {OUTPUT_FILE}\")\n",
    "print(f\"\\nâœ“ Analysis complete and ready for download!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDATA QUALITY CHECKS:\\n\")\n",
    "\n",
    "# Check 1: Missing values\n",
    "print(\"1. Missing Values in L2 Demand:\")\n",
    "missing_l2 = df_l2_demand.isnull().sum()\n",
    "if missing_l2.sum() > 0:\n",
    "    print(missing_l2[missing_l2 > 0])\n",
    "else:\n",
    "    print(\"   âœ“ No missing values\\n\")\n",
    "\n",
    "# Check 2: Data types\n",
    "print(\"2. Data Types:\")\n",
    "print(f\"   âœ“ EA values: {df_l2_demand['EA'].dtype}\")\n",
    "print(f\"   âœ“ Batches values: {df_l2_demand['Batches'].dtype}\\n\")\n",
    "\n",
    "# Check 3: Value ranges\n",
    "print(\"3. Value Ranges:\")\n",
    "print(f\"   â€¢ EA: min={df_l2_demand['EA'].min()}, max={df_l2_demand['EA'].max()}\")\n",
    "print(f\"   â€¢ Batches: min={df_l2_demand['Batches'].min()}, max={df_l2_demand['Batches'].max()}\")\n",
    "print(f\"   â€¢ Batch Size: min={df_l2_demand['Batch_Size'].min()}, max={df_l2_demand['Batch_Size'].max()}\\n\")\n",
    "\n",
    "# Check 4: Product coverage\n",
    "print(\"4. Product Coverage:\")\n",
    "for product in PRODUCTS_AVAILABLE:\n",
    "    count = len(df_l2_demand[df_l2_demand['Product_ID'] == product])\n",
    "    status = \"âœ“\" if count > 0 else \"âš \"\n",
    "    print(f\"   {status} Product {product}: {count} records\")\n",
    "\n",
    "print(\"\\nâœ“ Data quality checks complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
