{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths - UPDATE THESE IF FILES ARE IN DIFFERENT LOCATIONS\n",
    "AUG25_FILE = \"/home/supriyo/Downloads/Biocon_nw/Aug'25_L2_DP_Plan_Circulation_V2.xlsx\"\n",
    "SNP_FILE = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "BOM_FILE = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "OUTPUT_FILE = \"/mnt/user-data/outputs/Demand_Planning_Analysis.xlsx\"\n",
    "\n",
    "# Sheet Names\n",
    "AUG25_SHEET = \"L2Ph1_Detail\"\n",
    "SNP_SHEET = \"DP RCCP\"\n",
    "BOM_SHEET = \"DP Shortage\"\n",
    "\n",
    "# Products Configuration\n",
    "PRODUCTS_AVAILABLE = [700001012, 700001123, 700000536, 700001318, 700001301]\n",
    "PRODUCTS_NOT_AVAILABLE = [700004130]\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")\n",
    "print(f\"  Input files: 3\")\n",
    "print(f\"  Output file: {OUTPUT_FILE}\")\n",
    "print(f\"  Products to analyze: {len(PRODUCTS_AVAILABLE)}\")\n",
    "\n",
    "# ----- Input files & sheet configuration -----\n",
    "dp_file = \"/home/supriyo/Downloads/Biocon_nw/Aug'25_L2_DP_Plan_Circulation_V2.xlsx\"\n",
    "dp_sheet = \"L2Ph1_Detail\"\n",
    "dp_rows_start = 3\n",
    "dp_rows_end = 78  # inclusive\n",
    "market_sku_col = \"E\"\n",
    "batch_size_col = \"K\"\n",
    "product_id_col_hint = \"Product_Id\"  # we'll attempt to infer if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e8bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe91f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# EA / Batches columns (Excel letter ranges)\n",
    "ea_col_range = (\"S\", \"AM\")  # col S to AM (Oct-2025 .. Jun-2027) (21 months)\n",
    "batch_col_range = (\"AN\", \"BI\")  # col AN to BI (often 21 months; BI may be an extra/blank col in some files)\n",
    "\n",
    "# Output sheet for product demand\n",
    "output_sheet_name = \"Product_Demand\"\n",
    "\n",
    "# DP RCCP file\n",
    "rccp_file = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "rccp_sheet = \"DP RCCP\"\n",
    "rccp_product_id_col = \"C\"  # Product ID in column C (row 3 onward)\n",
    "rccp_key_figure_col = \"H\"  # \"Planned Production\" / \"Outbound Production Demand\"\n",
    "rccp_months_range = (\"J\", \"AD\")  # Mar-25 .. Apr-27 (24M is mentioned; actual columns ~21)\n",
    "\n",
    "# DP Shortage file for BOM mapping\n",
    "shortage_file = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "shortage_sheet = \"DP Shortage\"\n",
    "shortage_filter_rows = (23, 542)  # only use this slice\n",
    "shortage_product_id_col = \"A\"  # Product ID\n",
    "shortage_component_col = \"F\"   # Component ID / Material\n",
    "\n",
    "# Filled FG available in hierarchy\n",
    "filled_fg_available = ['700001012','700001123','700000536','700001318','700001301']\n",
    "filled_fg_not_available = ['700004130']  # explicitly not available\n",
    "\n",
    "# Provided product mapping (SKUs to hierarchy nodes)\n",
    "product_mapping = {}\n",
    "\n",
    "mCB_skus = ['800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "            '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "            '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380']\n",
    "\n",
    "sMCB_skus = ['800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "             '800006524', '800006627', '800007872']\n",
    "\n",
    "vial_skus = ['800004400', '800004401', '800006626', '800006740', '800007996']\n",
    "\n",
    "aspart_dlp_skus = ['800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691']\n",
    "\n",
    "aspart_vial_skus = ['800008017', '800006529']\n",
    "\n",
    "rhi_skus = ['800001300', '800001298', '800001299']\n",
    "\n",
    "for sku in mCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "\n",
    "for sku in sMCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "\n",
    "for sku in vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "\n",
    "for sku in aspart_dlp_skus:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "\n",
    "for sku in aspart_vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "\n",
    "for sku in rhi_skus:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "\n",
    "def excel_col_to_index(col_letter: str) -> int:\n",
    "    \"\"\"Convert Excel column letter (e.g., 'S') to 0-based pandas index.\"\"\"\n",
    "    col_letter = col_letter.upper()\n",
    "    exp = 0\n",
    "    col_index = 0\n",
    "    for char in reversed(col_letter):\n",
    "        col_index += (ord(char) - ord('A') + 1) * (26 ** exp)\n",
    "        exp += 1\n",
    "    return col_index - 1  # 0-based\n",
    "\n",
    "MONTH_ABBR_TO_NUM = {\n",
    "    'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "    'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "}\n",
    "\n",
    "def normalize_month_header(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert e.g., 'OCT 2025' -> '10.2025'; 'Mar-25' -> '3.2025'\n",
    "    Returns original string if it doesn't match expected patterns.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    s = str(name).strip()\n",
    "    # Pattern 1: 'OCT 2025'\n",
    "    m = re.match(r'^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-zA-Z]*\\s+(\\d{4})$', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        mon = m.group(1)[:3].upper()\n",
    "        yr = int(m.group(2))\n",
    "        return f\"{MONTH_ABBR_TO_NUM[mon]}.{yr}\"\n",
    "\n",
    "    # Pattern 2: 'Mar-25' or 'MAR-25'\n",
    "    m = re.match(r'^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-zA-Z]*[-_/](\\d{2,4})$', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        mon = m.group(1)[:3].upper()\n",
    "        y = m.group(2)\n",
    "        yr = int(y) + 2000 if len(y) == 2 else int(y)\n",
    "        return f\"{MONTH_ABBR_TO_NUM[mon]}.{yr}\"\n",
    "\n",
    "    # Pattern 3: already in '10.2025' or '10/2025' etc.\n",
    "    m = re.match(r'^(\\d{1,2})[\\./-](\\d{2,4})$', s)\n",
    "    if m:\n",
    "        mon = int(m.group(1))\n",
    "        y = m.group(2)\n",
    "        yr = int(y) + 2000 if len(y) == 2 else int(y)\n",
    "        return f\"{mon}.{yr}\"\n",
    "\n",
    "    return s\n",
    "\n",
    "def restrict_rows(df: pd.DataFrame, start_row: int, end_row: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Restrict a dataframe to Excel-like inclusive 1-based rows.\n",
    "    start_row/end_row are Excel row numbers. Pandas is 0-based; assume header is row 1.\n",
    "    \"\"\"\n",
    "    # If original data includes header as first row, data starts at Excel row 2.\n",
    "    # We will slice using iloc with start_row-1 to end_row-1 (0-based inclusive slice end handled via +1)\n",
    "    return df.iloc[start_row-1:end_row]\n",
    "\n",
    "def find_col_by_letter(df: pd.DataFrame, letter: str) -> str:\n",
    "    \"\"\"Return the df column name located at the given Excel column letter.\"\"\"\n",
    "    idx = excel_col_to_index(letter)\n",
    "    if idx < 0 or idx >= len(df.columns):\n",
    "        raise IndexError(f\"Column letter {letter} resolves to index {idx}, out of bounds for dataframe with {len(df.columns)} columns.\")\n",
    "    return df.columns[idx]\n",
    "\n",
    "def convert_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert all columns to numeric where possible.\"\"\"\n",
    "    return df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "def melt_months(df: pd.DataFrame, id_vars: List[str], month_cols: List[str], value_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Melt month columns to a long format with normalized Month.\"\"\"\n",
    "    tmp = df[id_vars + month_cols].copy()\n",
    "    melted = tmp.melt(id_vars=id_vars, value_vars=month_cols, var_name=\"MonthRaw\", value_name=value_name)\n",
    "    melted[\"Month\"] = melted[\"MonthRaw\"].apply(normalize_month_header)\n",
    "    melted.drop(columns=[\"MonthRaw\"], inplace=True)\n",
    "    # ensure numeric\n",
    "    melted[value_name] = pd.to_numeric(melted[value_name], errors=\"coerce\").fillna(0)\n",
    "    return melted\n",
    "\n",
    "# ---------- Processing DP file (EA/Batches from L2Ph1_Detail) ----------\n",
    "\n",
    "def process_dp_file() -> Tuple[pd.DataFrame, Dict[str, str]]:\n",
    "    if not os.path.exists(dp_file):\n",
    "        print(f\"DP file not found at: {dp_file}. Proceeding with empty template.\")\n",
    "        return pd.DataFrame(columns=[\"Market_SKU\",\"Batch_Size\",\"Product_Id\",\"Family\",\"Month\",\"EA\",\"Batches\"]), {}\n",
    "\n",
    "    df = pd.read_excel(dp_file, sheet_name=dp_sheet, header=0)\n",
    "    # Restrict to specified Excel rows (3..78 inclusive), excluding header row\n",
    "    df_slice = restrict_rows(df, dp_rows_start, dp_rows_end)\n",
    "\n",
    "    # Derive column names by letters\n",
    "    col_market_sku = find_col_by_letter(df, market_sku_col)\n",
    "    col_batch_size = find_col_by_letter(df, batch_size_col)\n",
    "\n",
    "    # Month columns ranges\n",
    "    ea_start, ea_end = excel_col_to_index(ea_col_range[0]), excel_col_to_index(ea_col_range[1])\n",
    "    batch_start, batch_end = excel_col_to_index(batch_col_range[0]), excel_col_to_index(batch_col_range[1])\n",
    "\n",
    "    ea_month_cols = list(df.columns[ea_start:ea_end+1])\n",
    "    batch_month_cols = list(df.columns[batch_start:batch_end+1])\n",
    "\n",
    "    # Normalize month headers preemptively\n",
    "    ea_month_norm = [normalize_month_header(c) for c in ea_month_cols]\n",
    "    batch_month_norm = [normalize_month_header(c) for c in batch_month_cols]\n",
    "\n",
    "    # Coerce numeric for month columns\n",
    "    df_slice[ea_month_cols] = convert_numeric(df_slice[ea_month_cols])\n",
    "    df_slice[batch_month_cols] = convert_numeric(df_slice[batch_month_cols])\n",
    "\n",
    "    # Build ID vars and melt\n",
    "    id_vars = [col_market_sku, col_batch_size]\n",
    "\n",
    "    ea_long = melt_months(df_slice, id_vars=id_vars, month_cols=ea_month_cols, value_name=\"EA\")\n",
    "    batch_long = melt_months(df_slice, id_vars=id_vars, month_cols=batch_month_cols, value_name=\"Batches\")\n",
    "\n",
    "    # Merge EA and Batches on identifiers + Month\n",
    "    merged = pd.merge(\n",
    "        ea_long[[col_market_sku, col_batch_size, \"Month\", \"EA\"]],\n",
    "        batch_long[[col_market_sku, col_batch_size, \"Month\", \"Batches\"]],\n",
    "        on=[col_market_sku, col_batch_size, \"Month\"],\n",
    "        how=\"outer\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Rename id columns\n",
    "    merged.rename(columns={col_market_sku: \"Market_SKU\", col_batch_size: \"Batch_Size\"}, inplace=True)\n",
    "\n",
    "    # Map Market_SKU to Product_Id via provided mapping (use 'filling' as Product_Id by default when available)\n",
    "    def map_product_id(sku: str) -> Tuple[str, str]:\n",
    "        sk = str(sku) if not pd.isna(sku) else \"\"\n",
    "        info = product_mapping.get(sk, {})\n",
    "        product = info.get(\"filling\") or info.get(\"assembly\") or info.get(\"root\")\n",
    "        fam = info.get(\"family\")\n",
    "        return product, fam\n",
    "\n",
    "    mapped = merged.copy()\n",
    "    mapped[[\"Product_Id\",\"Family\"]] = mapped[\"Market_SKU\"].apply(lambda x: pd.Series(map_product_id(x)))\n",
    "    # Filter rows where Product_Id is present\n",
    "    mapped = mapped[~mapped[\"Product_Id\"].isna()]\n",
    "\n",
    "    # Ensure Month is within Oct-2025 .. Jun-2027 inclusive\n",
    "    def month_to_tuple(mstr: str):\n",
    "        try:\n",
    "            m, y = mstr.split(\".\")\n",
    "            return int(y), int(m)\n",
    "        except Exception:\n",
    "            return (0, 0)\n",
    "\n",
    "    start_key = (2025, 10)\n",
    "    end_key = (2027, 6)\n",
    "    mapped = mapped[mapped[\"Month\"].apply(lambda v: start_key <= month_to_tuple(v) <= end_key)]\n",
    "\n",
    "    # Sort\n",
    "    mapped.sort_values(by=[\"Market_SKU\",\"Month\"], inplace=True)\n",
    "    return mapped, {\"ea_cols\": ea_month_cols, \"batch_cols\": batch_month_cols}\n",
    "\n",
    "# ---------- Processing DP RCCP (Planned Production / Outbound Production Demand) ----------\n",
    "\n",
    "def process_rccp_file() -> Dict[str, pd.DataFrame]:\n",
    "    results = {}\n",
    "    if not os.path.exists(rccp_file):\n",
    "        print(f\"RCCP file not found at: {rccp_file}. Proceeding with empty templates.\")\n",
    "        results[\"PlannedProduction\"] = pd.DataFrame(columns=[\"Product_ID\",\"Key_Figure\",\"Base_UOM\",\"Scenario\",\"Month\",\"Qty\"])\n",
    "        results[\"OutboundProductionDemand\"] = pd.DataFrame(columns=[\"Product_ID\",\"Key_Figure\",\"Base_UOM\",\"Scenario\",\"Month\",\"Qty\"])\n",
    "        return results\n",
    "\n",
    "    # Read with headers\n",
    "    rccp_df = pd.read_excel(rccp_file, sheet_name=rccp_sheet, header=0)\n",
    "\n",
    "    # Try to infer named columns (since provided are letters)\n",
    "    def colname_by_letter(df, letter):\n",
    "        try:\n",
    "            return find_col_by_letter(df, letter)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    col_prod = colname_by_letter(rccp_df, rccp_product_id_col) or \"Product ID\"\n",
    "    col_keyf = colname_by_letter(rccp_df, rccp_key_figure_col) or \"Key Figure\"\n",
    "\n",
    "    # Month columns by letters\n",
    "    m_start_idx = excel_col_to_index(rccp_months_range[0])\n",
    "    m_end_idx = excel_col_to_index(rccp_months_range[1])\n",
    "    rccp_month_cols = list(rccp_df.columns[m_start_idx:m_end_idx+1])\n",
    "\n",
    "    # Identify optional helpful columns if present\n",
    "    col_base_uom = \"Base UOM\" if \"Base UOM\" in rccp_df.columns else None\n",
    "    col_scenario = \"Scenario\" if \"Scenario\" in rccp_df.columns else None\n",
    "\n",
    "    # Coerce month columns numeric\n",
    "    rccp_df[rccp_month_cols] = convert_numeric(rccp_df[rccp_month_cols])\n",
    "\n",
    "    id_vars = [c for c in [col_prod, col_keyf, col_base_uom, col_scenario] if c]\n",
    "\n",
    "    rccp_long = melt_months(rccp_df, id_vars=id_vars, month_cols=rccp_month_cols, value_name=\"Qty\")\n",
    "\n",
    "    # Split by Key Figure\n",
    "    if col_keyf in rccp_long.columns:\n",
    "        pp = rccp_long[rccp_long[col_keyf].str.lower().eq(\"planned production\", na=False)].copy()\n",
    "        opd = rccp_long[rccp_long[col_keyf].str.lower().eq(\"outbound production demand\", na=False)].copy()\n",
    "    else:\n",
    "        pp = rccp_long.iloc[0:0].copy()\n",
    "        opd = rccp_long.iloc[0:0].copy()\n",
    "\n",
    "    # Normalize column names\n",
    "    def tidy(df):\n",
    "        out = df.rename(columns={col_prod: \"Product_ID\", col_keyf: \"Key_Figure\"})\n",
    "        if col_base_uom and col_base_uom in out.columns:\n",
    "            out.rename(columns={col_base_uom: \"Base_UOM\"}, inplace=True)\n",
    "        else:\n",
    "            out[\"Base_UOM\"] = np.nan\n",
    "        if col_scenario and col_scenario in out.columns:\n",
    "            out.rename(columns={col_scenario: \"Scenario\"}, inplace=True)\n",
    "        else:\n",
    "            out[\"Scenario\"] = np.nan\n",
    "        # Keep only the window Mar-2025 .. Apr-2027 if present\n",
    "        def month_tuple(mstr):\n",
    "            try:\n",
    "                m, y = mstr.split(\".\")\n",
    "                return int(y), int(m)\n",
    "            except Exception:\n",
    "                return (0, 0)\n",
    "        start_key = (2025, 3)\n",
    "        end_key = (2027, 4)\n",
    "        out = out[out[\"Month\"].apply(lambda v: start_key <= month_tuple(v) <= end_key)]\n",
    "        return out[[\"Product_ID\",\"Key_Figure\",\"Base_UOM\",\"Scenario\",\"Month\",\"Qty\"]]\n",
    "\n",
    "    results[\"PlannedProduction\"] = tidy(pp)\n",
    "    results[\"OutboundProductionDemand\"] = tidy(opd)\n",
    "    return results\n",
    "\n",
    "# ---------- BOM mapping using DP Shortage ----------\n",
    "\n",
    "def bom_demand_from_shortage(opd_long: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Using DP Shortage to map from a Finished Good Product_ID to its component materials (Component IDs),\n",
    "    then aggregate Outbound Production Demand from RCCP for those components, per month.\n",
    "    \"\"\"\n",
    "    if opd_long is None or opd_long.empty:\n",
    "        return pd.DataFrame(columns=[\"FG_Product_ID\",\"Component_ID\",\"Month\",\"Outbound_Prod_Demand\"])\n",
    "\n",
    "    if not os.path.exists(shortage_file):\n",
    "        print(f\"Shortage file not found at: {shortage_file}. Proceeding with empty template for BOM demand.\")\n",
    "        return pd.DataFrame(columns=[\"FG_Product_ID\",\"Component_ID\",\"Month\",\"Outbound_Prod_Demand\"])\n",
    "\n",
    "    # Load Shortage sheet; slice rows 23..542 (Excel numbering; header at 1), so pandas rows 22..541 (0-based)\n",
    "    sh_df = pd.read_excel(shortage_file, sheet_name=shortage_sheet, header=0)\n",
    "    sh_df = sh_df.iloc[shortage_filter_rows[0]-1:shortage_filter_rows[1]]\n",
    "\n",
    "    # Infer column names by letters (A=Product_ID, F=Component_ID)\n",
    "    try:\n",
    "        col_prodA = find_col_by_letter(sh_df, shortage_product_id_col)\n",
    "    except Exception:\n",
    "        # fallback find by name\n",
    "        col_prodA = \"Product_ID\" if \"Product_ID\" in sh_df.columns else (sh_df.columns[0] if len(sh_df.columns)>0 else None)\n",
    "\n",
    "    try:\n",
    "        col_compF = find_col_by_letter(sh_df, shortage_component_col)\n",
    "    except Exception:\n",
    "        # fallback by common names\n",
    "        col_compF = \"Component_ID\" if \"Component_ID\" in sh_df.columns else (sh_df.columns[5] if len(sh_df.columns)>5 else None)\n",
    "\n",
    "    if not col_prodA or not col_compF:\n",
    "        # Cannot proceed properly\n",
    "        return pd.DataFrame(columns=[\"FG_Product_ID\",\"Component_ID\",\"Month\",\"Outbound_Prod_Demand\"])\n",
    "\n",
    "    # Remove blanks / zeros\n",
    "    sh_df = sh_df[(sh_df[col_prodA].notna()) & (sh_df[col_prodA] != 0) & (sh_df[col_prodA] != \"\")]\n",
    "\n",
    "    # Focus only on the FG list provided (available ones)\n",
    "    sh_df = sh_df[sh_df[col_prodA].astype(str).isin(filled_fg_available)]\n",
    "\n",
    "    # Build mapping FG -> set(Components)\n",
    "    comp_map = (\n",
    "        sh_df[[col_prodA, col_compF]]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .groupby(col_prodA)[col_compF]\n",
    "        .agg(lambda s: sorted(set(s)))\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # For each FG, sum Outbound Production Demand for its components per month\n",
    "    rows = []\n",
    "    for fg, components in comp_map.items():\n",
    "        comp_rows = opd_long[opd_long[\"Product_ID\"].astype(str).isin(components)]\n",
    "        if comp_rows.empty:\n",
    "            continue\n",
    "        agg = comp_rows.groupby(\"Month\", as_index=False)[\"Qty\"].sum()\n",
    "        for _, r in agg.iterrows():\n",
    "            rows.append({\n",
    "                \"FG_Product_ID\": fg,\n",
    "                \"Component_ID\": \";\".join(components),\n",
    "                \"Month\": r[\"Month\"],\n",
    "                \"Outbound_Prod_Demand\": r[\"Qty\"]\n",
    "            })\n",
    "\n",
    "    result = pd.DataFrame(rows)\n",
    "    # Keep only the provided FG list\n",
    "    if not result.empty:\n",
    "        result = result[result[\"FG_Product_ID\"].isin(filled_fg_available)]\n",
    "        # Sort\n",
    "        def key(mstr):\n",
    "            try:\n",
    "                m, y = mstr.split(\".\")\n",
    "                return (int(y), int(m))\n",
    "            except Exception:\n",
    "                return (0, 0)\n",
    "        result.sort_values(by=[\"FG_Product_ID\",\"Month\"], key=lambda s: s.map(key), inplace=True)\n",
    "    return result\n",
    "\n",
    "# ---------- Run end-to-end and write outputs ----------\n",
    "\n",
    "product_demand_long, dp_meta = process_dp_file()\n",
    "rccp_results = process_rccp_file()\n",
    "planned_prod = rccp_results.get(\"PlannedProduction\", pd.DataFrame())\n",
    "opd = rccp_results.get(\"OutboundProductionDemand\", pd.DataFrame())\n",
    "bom_from_shortage = bom_demand_from_shortage(opd)\n",
    "\n",
    "# Prepare a compact \"example\" view for the requested header format:\n",
    "# Month | EA | Batches (for any one SKU as example if present)\n",
    "def compact_view(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame(columns=[\"Month\",\"EA\",\"Batches\"])\n",
    "    # Take first SKU present\n",
    "    sku = df[\"Market_SKU\"].iloc[0]\n",
    "    sub = df[df[\"Market_SKU\"] == sku][[\"Month\",\"EA\",\"Batches\"]].copy()\n",
    "    sub = sub.groupby(\"Month\", as_index=False).sum()\n",
    "    return sub\n",
    "\n",
    "compact = compact_view(product_demand_long)\n",
    "\n",
    "# Write to an output Excel file with multiple sheets\n",
    "out_path = \"/mnt/data/DP_RCCP_mapped_output.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "    product_demand_long.to_excel(writer, sheet_name=output_sheet_name, index=False)\n",
    "    planned_prod.to_excel(writer, sheet_name=\"RCCP_PlannedProduction\", index=False)\n",
    "    opd.to_excel(writer, sheet_name=\"RCCP_OutboundProdDemand\", index=False)\n",
    "    bom_from_shortage.to_excel(writer, sheet_name=\"BOM_OPD_Demand\", index=False)\n",
    "\n",
    "# Display previews (if non-empty)\n",
    "try:\n",
    "    from ace_tools import display_dataframe_to_user\n",
    "except Exception:\n",
    "    display_dataframe_to_user = None\n",
    "\n",
    "if display_dataframe_to_user:\n",
    "    if not product_demand_long.empty:\n",
    "        display_dataframe_to_user(\"Product_Demand (Oct-2025 to Jun-2027)\", product_demand_long.head(50))\n",
    "    if not planned_prod.empty:\n",
    "        display_dataframe_to_user(\"DP RCCP - Planned Production (Mar-2025 to Apr-2027)\", planned_prod.head(50))\n",
    "    if not opd.empty:\n",
    "        display_dataframe_to_user(\"DP RCCP - Outbound Production Demand (Mar-2025 to Apr-2027)\", opd.head(50))\n",
    "    if not bom_from_shortage.empty:\n",
    "        display_dataframe_to_user(\"BOM Demand from Shortage (OPD aggregated per FG)\", bom_from_shortage.head(50))\n",
    "    if not compact.empty:\n",
    "        display_dataframe_to_user(\"Compact Month | EA | Batches (first SKU example)\", compact)\n",
    "\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
