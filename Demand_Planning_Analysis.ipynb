{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7562607a",
   "metadata": {},
   "source": [
    "\n",
    "# Demand Planning Analysis (EA, Batches, RCCP & BOM Mapping)\n",
    "\n",
    "This notebook reads your **Aug'25 DP file**, **SNP RCCP file**, and **DP Shortage (BOM)** to produce:\n",
    "- Long-form `Product_Demand` (Month | EA | Batches) for rows 3–78 of `L2Ph1_Detail` (columns S:AM for EA, AN:BI for Batches).\n",
    "- `RCCP_PlannedProduction` and `RCCP_OutboundProdDemand` from `DP RCCP` (columns J:AD).\n",
    "- Aggregated component demand per FG using `DP Shortage` (rows 23–542), producing `BOM_OPD_Demand`.\n",
    "- Final Excel workbook saved to `OUTPUT_FILE`.\n",
    "\n",
    "> Month headers are normalized (e.g., **OCT 2025** → `10.2025`, **Mar-25** → `3.2025`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456e0eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Input files: 3\n",
      "  Output file: /home/supriyo/Downloads/Biocon_nw/Demand_Planning_Analysis.xlsx\n",
      "  Products to analyze: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== Configuration ====\n",
    "# File Paths - UPDATE THESE IF FILES ARE IN DIFFERENT LOCATIONS\n",
    "AUG25_FILE = \"/home/supriyo/Downloads/Biocon_nw/Aug'25_L2_DP_Plan_Circulation_V2.xlsx\"\n",
    "SNP_FILE = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "BOM_FILE = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "OUTPUT_FILE = \"/home/supriyo/Downloads/Biocon_nw/Demand_Planning_Analysis.xlsx\"  # will fall back to /mnt/data if not found\n",
    "\n",
    "# Sheet Names\n",
    "AUG25_SHEET = \"L2Ph1_Detail\"\n",
    "SNP_SHEET = \"DP RCCP\"\n",
    "BOM_SHEET = \"DP Shortage\"\n",
    "\n",
    "# Products Configuration\n",
    "PRODUCTS_AVAILABLE = [700001012, 700001123, 700000536, 700001318, 700001301]\n",
    "PRODUCTS_NOT_AVAILABLE = [700004130]\n",
    "\n",
    "# DP slicing configuration\n",
    "DP_ROWS_START = 3\n",
    "DP_ROWS_END = 78\n",
    "EA_COL_RANGE = (\"S\", \"AM\")  # Oct-2025 .. Jun-2027\n",
    "BATCH_COL_RANGE = (\"AN\", \"BI\")\n",
    "\n",
    "# RCCP column layout\n",
    "RCCP_PRODUCT_ID_COL = \"C\"  # Product ID\n",
    "RCCP_KEY_FIGURE_COL = \"H\"  # Key Figure\n",
    "RCCP_MONTHS_RANGE = (\"J\", \"AD\")  # Mar-2025 .. Apr-2027\n",
    "\n",
    "# Shortage sheet slicing + columns\n",
    "SHORTAGE_FILTER_ROWS = (23, 542)\n",
    "SHORTAGE_PRODUCT_ID_COL = \"A\"  # FG Product ID\n",
    "SHORTAGE_COMPONENT_COL = \"F\"   # Component/Material ID\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Input files: 3\")\n",
    "print(f\"  Output file: {OUTPUT_FILE}\")\n",
    "print(f\"  Products to analyze: {len(PRODUCTS_AVAILABLE)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde32d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Excel column letter to index ---\n",
    "def excel_col_to_index(col_letter: str) -> int:\n",
    "    col_letter = col_letter.upper().strip()\n",
    "    exp = 0\n",
    "    col_index = 0\n",
    "    for char in reversed(col_letter):\n",
    "        col_index += (ord(char) - ord('A') + 1) * (26 ** exp)\n",
    "        exp += 1\n",
    "    return col_index - 1  # 0-based\n",
    "\n",
    "# --- Month normalization ---\n",
    "MONTH_ABBR_TO_NUM = {\n",
    "    'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "    'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "}\n",
    "\n",
    "def normalize_month_header(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert e.g., 'OCT 2025' -> '10.2025'; 'Mar-25' -> '3.2025'; '10/2025' -> '10.2025'\n",
    "    Returns original string if it doesn't match expected patterns.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    s = str(name).strip()\n",
    "\n",
    "    m = re.match(r'^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-zA-Z]*\\s+(\\d{4})$', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        mon = m.group(1)[:3].upper()\n",
    "        yr = int(m.group(2))\n",
    "        return f\"{MONTH_ABBR_TO_NUM[mon]}.{yr}\"\n",
    "\n",
    "    m = re.match(r'^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-zA-Z]*[-_/](\\d{2,4})$', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        mon = m.group(1)[:3].upper()\n",
    "        y = m.group(2)\n",
    "        yr = int(y) + 2000 if len(y) == 2 else int(y)\n",
    "        return f\"{MONTH_ABBR_TO_NUM[mon]}.{yr}\"\n",
    "\n",
    "    m = re.match(r'^(\\d{1,2})[\\./-](\\d{2,4})$', s)\n",
    "    if m:\n",
    "        mon = int(m.group(1))\n",
    "        y = m.group(2)\n",
    "        yr = int(y) + 2000 if len(y) == 2 else int(y)\n",
    "        return f\"{mon}.{yr}\"\n",
    "\n",
    "    return s\n",
    "\n",
    "def restrict_rows(df: pd.DataFrame, start_row: int, end_row: int) -> pd.DataFrame:\n",
    "    \"\"\"Restrict dataframe to Excel-like inclusive rows (header assumed at row 1).\"\"\"\n",
    "    return df.iloc[start_row-1:end_row]\n",
    "\n",
    "def convert_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "def find_col_by_letter(df: pd.DataFrame, letter: str) -> str:\n",
    "    idx = excel_col_to_index(letter)\n",
    "    if idx < 0 or idx >= len(df.columns):\n",
    "        raise IndexError(f\"Column {letter} -> idx {idx} is out of bounds for {len(df.columns)} cols.\")\n",
    "    return df.columns[idx]\n",
    "\n",
    "def melt_months(df: pd.DataFrame, id_vars: List[str], month_cols: List[str], value_name: str) -> pd.DataFrame:\n",
    "    tmp = df[id_vars + month_cols].copy()\n",
    "    melted = tmp.melt(id_vars=id_vars, value_vars=month_cols, var_name=\"MonthRaw\", value_name=value_name)\n",
    "    melted[\"Month\"] = melted[\"MonthRaw\"].apply(normalize_month_header)\n",
    "    melted.drop(columns=[\"MonthRaw\"], inplace=True)\n",
    "    melted[value_name] = pd.to_numeric(melted[value_name], errors=\"coerce\").fillna(0)\n",
    "    return melted\n",
    "\n",
    "def ensure_output_path(path: str) -> str:\n",
    "    \"\"\"Ensure directory exists; if not, fallback to /mnt/data/Demand_Planning_Analysis.xlsx\"\"\"\n",
    "    directory = os.path.dirname(path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        print(f\"Output directory not found: {directory}. Falling back to /mnt/data.\")\n",
    "        return \"/mnt/data/Demand_Planning_Analysis.xlsx\"\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d79089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy defined with 52 SKU mappings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- SKU to hierarchy mapping ---\n",
    "product_mapping: Dict[str, Dict[str,str]] = {}\n",
    "\n",
    "mCB_skus = ['800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "            '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "            '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380']\n",
    "\n",
    "sMCB_skus = ['800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "             '800006524', '800006627', '800007872']\n",
    "\n",
    "vial_skus = ['800004400', '800004401', '800006626', '800006740', '800007996']\n",
    "\n",
    "aspart_dlp_skus = ['800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691']\n",
    "\n",
    "aspart_vial_skus = ['800008017', '800006529']\n",
    "\n",
    "rhi_skus = ['800001300', '800001298', '800001299']\n",
    "\n",
    "for sku in mCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "\n",
    "for sku in sMCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "\n",
    "for sku in vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "\n",
    "for sku in aspart_dlp_skus:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "\n",
    "for sku in aspart_vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "\n",
    "for sku in rhi_skus:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\n",
    "print(f\"Hierarchy defined with {len(product_mapping)} SKU mappings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90316ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Demand rows: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_399851/423144278.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_slice[ea_month_cols] = convert_numeric(df_slice[ea_month_cols])\n",
      "/tmp/ipykernel_399851/423144278.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_slice[batch_month_cols] = convert_numeric(df_slice[batch_month_cols])\n",
      "/tmp/ipykernel_399851/423144278.py:35: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Process Aug'25 DP file (EA & Batches) ---\n",
    "if not os.path.exists(AUG25_FILE):\n",
    "    print(f\"DP file not found: {AUG25_FILE}. The pipeline will continue but Product_Demand will be empty.\")\n",
    "    product_demand_long = pd.DataFrame(columns=[\"Market_SKU\",\"Batch_Size\",\"Product_Id\",\"Family\",\"Month\",\"EA\",\"Batches\"])\n",
    "else:\n",
    "    df = pd.read_excel(AUG25_FILE, sheet_name=AUG25_SHEET, header=0)\n",
    "    df_slice = restrict_rows(df, DP_ROWS_START, DP_ROWS_END)\n",
    "\n",
    "    # Identify Market SKU & Batch Size columns by letters (E and K)\n",
    "    market_sku_col = find_col_by_letter(df, \"E\")\n",
    "    batch_size_col = find_col_by_letter(df, \"K\")\n",
    "\n",
    "    ea_start_idx = excel_col_to_index(EA_COL_RANGE[0])\n",
    "    ea_end_idx = excel_col_to_index(EA_COL_RANGE[1])\n",
    "    batch_start_idx = excel_col_to_index(BATCH_COL_RANGE[0])\n",
    "    batch_end_idx = excel_col_to_index(BATCH_COL_RANGE[1])\n",
    "\n",
    "    ea_month_cols = list(df.columns[ea_start_idx:ea_end_idx+1])\n",
    "    batch_month_cols = list(df.columns[batch_start_idx:batch_end_idx+1])\n",
    "\n",
    "    # Coerce numeric for month columns\n",
    "    df_slice[ea_month_cols] = convert_numeric(df_slice[ea_month_cols])\n",
    "    df_slice[batch_month_cols] = convert_numeric(df_slice[batch_month_cols])\n",
    "\n",
    "    id_vars = [market_sku_col, batch_size_col]\n",
    "\n",
    "    ea_long = melt_months(df_slice, id_vars=id_vars, month_cols=ea_month_cols, value_name=\"EA\")\n",
    "    batch_long = melt_months(df_slice, id_vars=id_vars, month_cols=batch_month_cols, value_name=\"Batches\")\n",
    "\n",
    "    merged = pd.merge(\n",
    "        ea_long[[market_sku_col, batch_size_col, \"Month\", \"EA\"]],\n",
    "        batch_long[[market_sku_col, batch_size_col, \"Month\", \"Batches\"]],\n",
    "        on=[market_sku_col, batch_size_col, \"Month\"],\n",
    "        how=\"outer\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    merged.rename(columns={market_sku_col: \"Market_SKU\", batch_size_col: \"Batch_Size\"}, inplace=True)\n",
    "\n",
    "    # Map Market_SKU -> Product_Id (prefer 'filling'), and add Family\n",
    "    def map_product_id(sku: str):\n",
    "        sk = str(sku) if not pd.isna(sku) else \"\"\n",
    "        info = product_mapping.get(sk, {})\n",
    "        return pd.Series([info.get(\"filling\") or info.get(\"assembly\") or info.get(\"root\"), info.get(\"family\")])\n",
    "\n",
    "    merged[[\"Product_Id\",\"Family\"]] = merged[\"Market_SKU\"].apply(map_product_id)\n",
    "    product_demand_long = merged[~merged[\"Product_Id\"].isna()].copy()\n",
    "\n",
    "    # Keep only Oct-2025 .. Jun-2027\n",
    "    def key(mstr):\n",
    "        try:\n",
    "            m, y = mstr.split(\".\")\n",
    "            return (int(y), int(m))\n",
    "        except Exception:\n",
    "            return (0, 0)\n",
    "    product_demand_long = product_demand_long[product_demand_long[\"Month\"].apply(lambda v: (2025,10) <= key(v) <= (2027,6))]\n",
    "    product_demand_long.sort_values(by=[\"Market_SKU\",\"Month\"], inplace=True)\n",
    "\n",
    "print(\"Product_Demand rows:\", len(product_demand_long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc45b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCCP Planned Production rows: 0\n",
      "RCCP Outbound Production Demand rows: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Process SNP RCCP (Planned Production & Outbound Production Demand) ---\n",
    "if not os.path.exists(SNP_FILE):\n",
    "    print(f\"RCCP file not found: {SNP_FILE}. RCCP outputs will be empty.\")\n",
    "    rccp_planned = pd.DataFrame(columns=[\"Product_ID\",\"Key_Figure\",\"Base_UOM\",\"Scenario\",\"Month\",\"Qty\"])\n",
    "    rccp_opd = pd.DataFrame(columns=[\"Product_ID\",\"Key_Figure\",\"Base_UOM\",\"Scenario\",\"Month\",\"Qty\"])\n",
    "else:\n",
    "    rccp_df = pd.read_excel(SNP_FILE, sheet_name=SNP_SHEET, header=0)\n",
    "\n",
    "    # Map letters to columns\n",
    "    prod_col = find_col_by_letter(rccp_df, RCCP_PRODUCT_ID_COL)\n",
    "    keyf_col = find_col_by_letter(rccp_df, RCCP_KEY_FIGURE_COL)\n",
    "\n",
    "    m_start_idx = excel_col_to_index(RCCP_MONTHS_RANGE[0])\n",
    "    m_end_idx = excel_col_to_index(RCCP_MONTHS_RANGE[1])\n",
    "    rccp_month_cols = list(rccp_df.columns[m_start_idx:m_end_idx+1])\n",
    "\n",
    "    # Optional columns\n",
    "    base_uom_col = \"Base UOM\" if \"Base UOM\" in rccp_df.columns else None\n",
    "    scenario_col = \"Scenario\" if \"Scenario\" in rccp_df.columns else None\n",
    "\n",
    "    rccp_df[rccp_month_cols] = convert_numeric(rccp_df[rccp_month_cols])\n",
    "\n",
    "    id_vars = [c for c in [prod_col, keyf_col, base_uom_col, scenario_col] if c]\n",
    "    rccp_long = rccp_df[id_vars + rccp_month_cols].melt(\n",
    "        id_vars=id_vars, value_vars=rccp_month_cols, var_name=\"MonthRaw\", value_name=\"Qty\"\n",
    "    )\n",
    "    rccp_long[\"Month\"] = rccp_long[\"MonthRaw\"].apply(normalize_month_header)\n",
    "    rccp_long[\"Qty\"] = pd.to_numeric(rccp_long[\"Qty\"], errors=\"coerce\").fillna(0)\n",
    "    rccp_long.drop(columns=[\"MonthRaw\"], inplace=True)\n",
    "\n",
    "    # Window Mar-2025 .. Apr-2027\n",
    "    def in_window(mstr):\n",
    "        try:\n",
    "            m, y = mstr.split(\".\")\n",
    "            return (2025,3) <= (int(y), int(m)) <= (2027,4)\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    rccp_long = rccp_long[rccp_long[\"Month\"].apply(in_window)]\n",
    "\n",
    "    # Split by Key Figure (case-insensitive)\n",
    "    mask_pp = rccp_long[keyf_col].str.lower().eq(\"planned production\")\n",
    "    mask_opd = rccp_long[keyf_col].str.lower().eq(\"outbound production demand\")\n",
    "\n",
    "    def tidy(df):\n",
    "        out = df.rename(columns={prod_col:\"Product_ID\", keyf_col:\"Key_Figure\"}).copy()\n",
    "        if base_uom_col and base_uom_col in out.columns:\n",
    "            out.rename(columns={base_uom_col:\"Base_UOM\"}, inplace=True)\n",
    "        else:\n",
    "            out[\"Base_UOM\"] = np.nan\n",
    "        if scenario_col and scenario_col in out.columns:\n",
    "            out.rename(columns={scenario_col:\"Scenario\"}, inplace=True)\n",
    "        else:\n",
    "            out[\"Scenario\"] = np.nan\n",
    "        return out[[\"Product_ID\",\"Key_Figure\",\"Base_UOM\",\"Scenario\",\"Month\",\"Qty\"]]\n",
    "\n",
    "    rccp_planned = tidy(rccp_long[mask_pp])\n",
    "    rccp_opd = tidy(rccp_long[mask_opd])\n",
    "\n",
    "print(\"RCCP Planned Production rows:\", len(rccp_planned))\n",
    "print(\"RCCP Outbound Production Demand rows:\", len(rccp_opd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6d807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOM_OPD_Demand rows: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- BOM mapping via DP Shortage (aggregate OPD by components per FG) ---\n",
    "if not os.path.exists(BOM_FILE):\n",
    "    print(f\"Shortage file not found: {BOM_FILE}. BOM_OPD_Demand will be empty.\")\n",
    "    bom_opd = pd.DataFrame(columns=[\"FG_Product_ID\",\"Component_ID\",\"Month\",\"Outbound_Prod_Demand\"])\n",
    "else:\n",
    "    sh_df = pd.read_excel(BOM_FILE, sheet_name=BOM_SHEET, header=0)\n",
    "    sh_df = sh_df.iloc[SHORTAGE_FILTER_ROWS[0]-1:SHORTAGE_FILTER_ROWS[1]]\n",
    "\n",
    "    # Infer columns A (FG Product_ID) & F (Component_ID)\n",
    "    try:\n",
    "        col_prodA = sh_df.columns[excel_col_to_index(SHORTAGE_PRODUCT_ID_COL)]\n",
    "    except Exception:\n",
    "        col_prodA = \"Product_ID\" if \"Product_ID\" in sh_df.columns else sh_df.columns[0]\n",
    "\n",
    "    try:\n",
    "        col_compF = sh_df.columns[excel_col_to_index(SHORTAGE_COMPONENT_COL)]\n",
    "    except Exception:\n",
    "        col_compF = \"Component_ID\" if \"Component_ID\" in sh_df.columns else sh_df.columns[5]\n",
    "\n",
    "    sh_df = sh_df[(sh_df[col_prodA].notna()) & (sh_df[col_prodA] != 0) & (sh_df[col_prodA] != \"\")]\n",
    "    sh_df[col_prodA] = sh_df[col_prodA].astype(str)\n",
    "\n",
    "    # Keep only available FG list\n",
    "    avail_str = set(map(str, PRODUCTS_AVAILABLE))\n",
    "    sh_df = sh_df[sh_df[col_prodA].isin(avail_str)]\n",
    "\n",
    "    # Map FG -> components\n",
    "    comp_map = (sh_df[[col_prodA, col_compF]]\n",
    "                .dropna()\n",
    "                .astype(str)\n",
    "                .groupby(col_prodA)[col_compF]\n",
    "                .agg(lambda s: sorted(set(s)))\n",
    "                .to_dict())\n",
    "\n",
    "    rows = []\n",
    "    if not rccp_opd.empty:\n",
    "        for fg, comps in comp_map.items():\n",
    "            comp_rows = rccp_opd[rccp_opd[\"Product_ID\"].astype(str).isin(set(comps))]\n",
    "            if comp_rows.empty:\n",
    "                continue\n",
    "            agg = comp_rows.groupby(\"Month\", as_index=False)[\"Qty\"].sum()\n",
    "            for _, rec in agg.iterrows():\n",
    "                rows.append({\n",
    "                    \"FG_Product_ID\": fg,\n",
    "                    \"Component_ID\": \";\".join(comps),\n",
    "                    \"Month\": rec[\"Month\"],\n",
    "                    \"Outbound_Prod_Demand\": rec[\"Qty\"]\n",
    "                })\n",
    "    bom_opd = pd.DataFrame(rows)\n",
    "\n",
    "    if not bom_opd.empty:\n",
    "        def sortkey(mstr):\n",
    "            try:\n",
    "                m, y = mstr.split(\".\")\n",
    "                return (int(y), int(m))\n",
    "            except Exception:\n",
    "                return (0, 0)\n",
    "        bom_opd = bom_opd[bom_opd[\"FG_Product_ID\"].isin(list(map(str, PRODUCTS_AVAILABLE)))]\n",
    "        bom_opd.sort_values(by=[\"FG_Product_ID\",\"Month\"], key=lambda s: s.map(sortkey), inplace=True)\n",
    "\n",
    "print(\"BOM_OPD_Demand rows:\", len(bom_opd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a2d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrote Excel output to: /home/supriyo/Downloads/Biocon_nw/Demand_Planning_Analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Save all outputs to Excel ---\n",
    "final_output = ensure_output_path(OUTPUT_FILE)\n",
    "with pd.ExcelWriter(final_output, engine=\"openpyxl\") as writer:\n",
    "    (product_demand_long if 'product_demand_long' in globals() else pd.DataFrame()).to_excel(writer, sheet_name=\"Product_Demand\", index=False)\n",
    "    (rccp_planned if 'rccp_planned' in globals() else pd.DataFrame()).to_excel(writer, sheet_name=\"RCCP_PlannedProduction\", index=False)\n",
    "    (rccp_opd if 'rccp_opd' in globals() else pd.DataFrame()).to_excel(writer, sheet_name=\"RCCP_OutboundProdDemand\", index=False)\n",
    "    (bom_opd if 'bom_opd' in globals() else pd.DataFrame()).to_excel(writer, sheet_name=\"BOM_OPD_Demand\", index=False)\n",
    "\n",
    "print(f\"✓ Wrote Excel output to: {final_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed948656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optional: Compact Month|EA|Batches preview for the first SKU (for quick QA) ---\n",
    "def compact_view(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame(columns=[\"Month\",\"EA\",\"Batches\"])\n",
    "    sku = df[\"Market_SKU\"].iloc[0]\n",
    "    sub = df[df[\"Market_SKU\"] == sku][[\"Month\",\"EA\",\"Batches\"]].copy()\n",
    "    sub = sub.groupby(\"Month\", as_index=False).sum()\n",
    "    return sub\n",
    "\n",
    "try:\n",
    "    from ace_tools import display_dataframe_to_user\n",
    "    preview = compact_view(product_demand_long if 'product_demand_long' in globals() else pd.DataFrame())\n",
    "    if not preview.empty:\n",
    "        display_dataframe_to_user(\"Compact Month | EA | Batches (first SKU example)\", preview)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
