{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material Pegging Map - Per-SKU Pegging with Complete Hierarchy\n",
    "## Each Market SKU sheet shows: Packing -> Assembly -> Filling hierarchy\n",
    "\n",
    "**Output:** Material_pegging_SKU_2_BOM.xlsx\n",
    "\n",
    "**Sheet Structure:** Pegging_{8-series SKU}\n",
    "\n",
    "**Hierarchy per SKU:**\n",
    "- Level 1: Market SKU (800004403) + Materials\n",
    "- Separator: 0\n",
    "- Level 2: Assembly (700003964) + Materials\n",
    "- Separator: 0\n",
    "- Level 3: Filling (700001012) + Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "MATERIAL PEGGING MAP - PER-SKU PEGGING WITH COMPLETE HIERARCHY\n",
      "========================================================================================================================\n",
      "Output: /home/supriyo/Downloads/Biocon_nw/Material_pegging_SKU_2_BOM.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"MATERIAL PEGGING MAP - PER-SKU PEGGING WITH COMPLETE HIERARCHY\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "dp_file = \"/home/supriyo/Downloads/Biocon_nw/20251006-DP Material Shortage - Working file.xlsx\"\n",
    "snp_file = \"/home/supriyo/Downloads/Biocon_nw/ParkourSC_SNP.xlsx\"\n",
    "output_file = \"/home/supriyo/Downloads/Biocon_nw/Material_pegging_SKU_2_BOM.xlsx\"\n",
    "\n",
    "print(f\"Output: {output_file}\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return None\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'\\\\s+', ' ', text)\n",
    "    return text if text else None\n",
    "\n",
    "def normalize_product_no(value):\n",
    "    if pd.isna(value) or value is None:\n",
    "        return None\n",
    "    text = str(value).strip()\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9]', '', text)\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "def extract_model_components(model_text):\n",
    "    if pd.isna(model_text):\n",
    "        return None\n",
    "    model_text = str(model_text).strip()\n",
    "    components = re.split(r'_+', model_text)\n",
    "    components = [c.strip() for c in components if c.strip()]\n",
    "    return '_'.join(components)\n",
    "\n",
    "def is_valid_qty(qty):\n",
    "    if pd.isna(qty):\n",
    "        return False\n",
    "    qty_str = str(qty).strip()\n",
    "    if not qty_str or qty_str == '0' or qty_str == 'nan':\n",
    "        return False\n",
    "    try:\n",
    "        return float(qty_str) > 0\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Product headers: 87\n",
      "Materials: 520\n",
      "Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "df_headers = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=18, nrows=4, usecols=range(14, 135))\n",
    "product_headers = {}\n",
    "for col_idx in range(df_headers.shape[1]):\n",
    "    product_id = normalize_product_no(df_headers.iloc[1, col_idx])\n",
    "    if product_id and product_id != '0':\n",
    "        product_headers[product_id] = {\n",
    "            'Product_ID': product_id,\n",
    "            'Product_Description': normalize_text(df_headers.iloc[3, col_idx]),\n",
    "            'Batch_Size': df_headers.iloc[0, col_idx],\n",
    "            'Column_Index': col_idx + 14\n",
    "        }\n",
    "\n",
    "print(f\"Product headers: {len(product_headers)}\")\n",
    "\n",
    "df_materials = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=22, nrows=520, usecols=[0, 1, 2, 3, 4, 5, 10, 13])\n",
    "df_materials.columns = ['Material', 'Material_Description', 'Model', 'Product_Family', 'Section', 'Common_Unique', 'Total_Lead_Time', 'BUoM']\n",
    "df_materials['Material_Normalized'] = df_materials['Material'].apply(normalize_product_no)\n",
    "df_materials_filtered = df_materials[(df_materials['Material_Normalized'].notna()) & (df_materials['Material_Normalized'] != '0')].copy()\n",
    "print(f\"Materials: {len(df_materials_filtered)}\")\n",
    "\n",
    "df_qty = pd.read_excel(dp_file, sheet_name=\"DP Shortage\", header=None, skiprows=22, nrows=520, usecols=range(14, 135))\n",
    "qty_col_map = {}\n",
    "for product_id, info in product_headers.items():\n",
    "    qty_col_map[product_id] = info['Column_Index'] - 14\n",
    "\n",
    "print(\"Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting materials per product...\n",
      "Extracted for 87 products\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting materials per product...\")\n",
    "product_materials = {}\n",
    "\n",
    "for product_id, col_idx_in_qty in qty_col_map.items():\n",
    "    qty_values = df_qty.iloc[:, col_idx_in_qty]\n",
    "    valid_qty_mask = qty_values.apply(is_valid_qty)\n",
    "    valid_row_indices = df_materials_filtered.index[valid_qty_mask[df_materials_filtered.index]].tolist()\n",
    "    \n",
    "    if len(valid_row_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    materials_for_product = df_materials_filtered.loc[valid_row_indices].copy()\n",
    "    materials_for_product['QTY'] = qty_values[valid_row_indices].values\n",
    "    materials_for_product['Product_ID'] = product_id\n",
    "    product_materials[product_id] = materials_for_product\n",
    "\n",
    "print(f\"Extracted for {len(product_materials)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Resource and SKU data...\n",
      "Resource data: 64\n",
      "SKU data: 76\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Resource and SKU data...\")\n",
    "\n",
    "resource_data = {}\n",
    "try:\n",
    "    df_resources = pd.read_excel(snp_file, sheet_name=\"DP Line Utilization\", header=None, skiprows=2, nrows=240, usecols=[1, 2, 4])\n",
    "    df_resources.columns = ['Resource_ID', 'Resource_Description', 'Product_ID']\n",
    "    for _, row in df_resources.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id:\n",
    "            resource_data[prod_id] = {\n",
    "                'Resource_ID': normalize_text(row['Resource_ID']),\n",
    "                'Resource_Description': normalize_text(row['Resource_Description'])\n",
    "            }\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "\n",
    "sku_data = {}\n",
    "try:\n",
    "    df_adv = pd.read_excel(snp_file, sheet_name=\"Adv Mkt-Mar'25\", header=None, skiprows=2, nrows=363, usecols=[1, 3, 5, 8])\n",
    "    df_adv.columns = ['Product_ID', 'SKU', 'Country', 'Pack_Size']\n",
    "    for _, row in df_adv.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id and prod_id not in sku_data:\n",
    "            sku_data[prod_id] = {'SKU': normalize_text(row['SKU']), 'Country': normalize_text(row['Country']), 'Pack_Size': row['Pack_Size']}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df_em = pd.read_excel(snp_file, sheet_name=\"EM-Mar'25\", header=None, skiprows=2, nrows=44, usecols=[1, 6, 12, 14])\n",
    "    df_em.columns = ['Product_ID', 'SKU', 'Country', 'Pack_Size']\n",
    "    for _, row in df_em.iterrows():\n",
    "        prod_id = normalize_product_no(row['Product_ID'])\n",
    "        if prod_id and prod_id not in sku_data:\n",
    "            sku_data[prod_id] = {'SKU': normalize_text(row['SKU']), 'Country': normalize_text(row['Country']), 'Pack_Size': row['Pack_Size']}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(f\"Resource data: {len(resource_data)}\")\n",
    "print(f\"SKU data: {len(sku_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining hierarchy...\n",
      "Hierarchy defined with 52 SKU mappings\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining hierarchy...\")\n",
    "\n",
    "product_mapping = {}\n",
    "\n",
    "mCB_skus = ['800004403', '800004402', '800008019', '800008020', '800008034', '800007997', '800007345', '800007516',\n",
    "            '800002513', '800007608', '800007630', '800002984', '800004986', '800007310', '800007311', '800006648',\n",
    "            '800007634', '800008073', '800006523', '800002297', '800002872', '800006741', '800007380']\n",
    "\n",
    "sMCB_skus = ['800006506', '800006505', '800006527', '800006526', '800006525', '800007546', '800007583', '800007839',\n",
    "             '800006524', '800006627', '800007872']\n",
    "\n",
    "vial_skus = ['800004400', '800004401', '800006626', '800006740', '800007996']\n",
    "\n",
    "aspart_dlp_skus = ['800008016', '800002958', '800002948', '800006528', '800002989', '800003528', '800006592', '800006691']\n",
    "\n",
    "aspart_vial_skus = ['800008017', '800006529']\n",
    "\n",
    "rhi_skus = ['800001300', '800001298', '800001299']\n",
    "\n",
    "for sku in mCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700003964', 'filling': '700001012', 'root': '700001470', 'family': 'Glargine_mCB_DLP'}\n",
    "\n",
    "for sku in sMCB_skus:\n",
    "    product_mapping[sku] = {'assembly': '700004129', 'filling': '700004130', 'root': '700004130', 'family': 'Glargine_sMCB_DLP_EU'}\n",
    "\n",
    "for sku in vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001123', 'filling': '700001123', 'root': '700001123', 'family': 'Glargine_Vial'}\n",
    "\n",
    "for sku in aspart_dlp_skus:\n",
    "    product_mapping[sku] = {'assembly': '700002770', 'filling': '700001301', 'root': '700001301', 'family': 'Aspart_DLP'}\n",
    "\n",
    "for sku in aspart_vial_skus:\n",
    "    product_mapping[sku] = {'assembly': '700001318', 'filling': '700001318', 'root': '700001318', 'family': 'Aspart_Vial'}\n",
    "\n",
    "for sku in rhi_skus:\n",
    "    product_mapping[sku] = {'assembly': '700000536', 'filling': '700000536', 'root': '700000536', 'family': 'RHI'}\n",
    "\n",
    "print(f\"Hierarchy defined with {len(product_mapping)} SKU mappings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating per-SKU pegging sheets...\n",
      "Created pegging sheets for 52 market SKUs\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating per-SKU pegging sheets...\")\n",
    "\n",
    "output_cols = ['BOM_Type', 'BOM_Level', 'Product_ID', 'Product_Description', 'SKU', 'Country', 'Pack_Size',\n",
    "               'Material', 'Material_Description', 'QTY', 'Section', 'Product_Family', 'Common_Unique',\n",
    "               'Total_Lead_Time', 'BUoM', 'Model', 'Resource_ID', 'Resource_Description', 'Batch_Size']\n",
    "\n",
    "sku_pegging_sheets = {}\n",
    "\n",
    "for market_sku, mapping_info in sorted(product_mapping.items()):\n",
    "    assembly_id = mapping_info.get('assembly')\n",
    "    filling_id = mapping_info.get('filling')\n",
    "    family_name = mapping_info.get('family', 'Unknown')\n",
    "    \n",
    "    pegging_data = []\n",
    "    \n",
    "    if market_sku in product_materials:\n",
    "        for _, mat_row in product_materials[market_sku].iterrows():\n",
    "            sku_info = sku_data.get(market_sku, {})\n",
    "            product_info = product_headers.get(market_sku, {})\n",
    "            resource_info = resource_data.get(market_sku, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Packing',\n",
    "                'BOM_Level': 'L1_Market_SKU',\n",
    "                'Product_ID': market_sku,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': sku_info.get('SKU', 'N/A'),\n",
    "                'Country': sku_info.get('Country', 'N/A'),\n",
    "                'Pack_Size': sku_info.get('Pack_Size', 'N/A'),\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    pegging_data.append({col: '0' if col == 'Product_ID' else None for col in output_cols})\n",
    "    \n",
    "    if assembly_id != market_sku and assembly_id in product_materials:\n",
    "        for _, mat_row in product_materials[assembly_id].iterrows():\n",
    "            product_info = product_headers.get(assembly_id, {})\n",
    "            resource_info = resource_data.get(assembly_id, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Assembly',\n",
    "                'BOM_Level': 'L2_Assembly',\n",
    "                'Product_ID': assembly_id,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': 'N/A',\n",
    "                'Country': 'N/A',\n",
    "                'Pack_Size': 'N/A',\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    pegging_data.append({col: '0' if col == 'Product_ID' else None for col in output_cols})\n",
    "    \n",
    "    if filling_id != assembly_id and filling_id in product_materials:\n",
    "        for _, mat_row in product_materials[filling_id].iterrows():\n",
    "            product_info = product_headers.get(filling_id, {})\n",
    "            resource_info = resource_data.get(filling_id, {})\n",
    "            \n",
    "            pegging_data.append({\n",
    "                'BOM_Type': 'Filling',\n",
    "                'BOM_Level': 'L3_Filling',\n",
    "                'Product_ID': filling_id,\n",
    "                'Product_Description': product_info.get('Product_Description', 'N/A'),\n",
    "                'SKU': 'N/A',\n",
    "                'Country': 'N/A',\n",
    "                'Pack_Size': 'N/A',\n",
    "                'Material': normalize_text(mat_row['Material_Normalized']),\n",
    "                'Material_Description': normalize_text(mat_row['Material_Description']),\n",
    "                'QTY': mat_row['QTY'],\n",
    "                'Section': normalize_text(mat_row['Section']),\n",
    "                'Product_Family': family_name,\n",
    "                'Common_Unique': normalize_text(mat_row['Common_Unique']),\n",
    "                'Total_Lead_Time': mat_row['Total_Lead_Time'],\n",
    "                'BUoM': normalize_text(mat_row['BUoM']),\n",
    "                'Model': extract_model_components(mat_row['Model']),\n",
    "                'Resource_ID': resource_info.get('Resource_ID', 'N/A'),\n",
    "                'Resource_Description': resource_info.get('Resource_Description', 'N/A'),\n",
    "                'Batch_Size': product_info.get('Batch_Size', 'N/A')\n",
    "            })\n",
    "    \n",
    "    df_pegging = pd.DataFrame(pegging_data)[output_cols]\n",
    "    sku_pegging_sheets[market_sku] = df_pegging\n",
    "\n",
    "print(f\"Created pegging sheets for {len(sku_pegging_sheets)} market SKUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to Excel...\n",
      "  Exported 10/52 SKU pegging sheets\n",
      "  Exported 20/52 SKU pegging sheets\n",
      "  Exported 30/52 SKU pegging sheets\n",
      "  Exported 40/52 SKU pegging sheets\n",
      "  Exported 50/52 SKU pegging sheets\n",
      "  Exported 52/52 SKU pegging sheets\n",
      "\n",
      "Exported: /home/supriyo/Downloads/Biocon_nw/Material_pegging_SKU_2_BOM.xlsx\n",
      "Total sheets: 52\n",
      "Time: 19.76s\n"
     ]
    }
   ],
   "source": [
    "print(\"Exporting to Excel...\")\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for idx, (sku, pegging_df) in enumerate(sorted(sku_pegging_sheets.items()), 1):\n",
    "        sheet_name = f\"Pegging_{sku}\"[:31]\n",
    "        pegging_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        if idx % 10 == 0 or idx == len(sku_pegging_sheets):\n",
    "            print(f\"  Exported {idx}/{len(sku_pegging_sheets)} SKU pegging sheets\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nExported: {output_file}\")\n",
    "print(f\"Total sheets: {len(sku_pegging_sheets)}\")\n",
    "print(f\"Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "PER-SKU PEGGING SUMMARY\n",
      "========================================================================================================================\n",
      "\n",
      "FILE: Material_pegging_SKU_2_BOM.xlsx\n",
      "\n",
      "TOTAL SKU PEGGING SHEETS: 52\n",
      "\n",
      "SHEET STRUCTURE (Per Market SKU):\n",
      "  Level 1 (Packing): Market SKU materials\n",
      "  Separator: 0 (Product_ID column only)\n",
      "  Level 2 (Assembly): Assembly materials\n",
      "  Separator: 0 (Product_ID column only)\n",
      "  Level 3 (Filling): Filling materials\n",
      "\n",
      "COLUMNS (19 total):\n",
      "   1. BOM_Type\n",
      "   2. BOM_Level\n",
      "   3. Product_ID\n",
      "   4. Product_Description\n",
      "   5. SKU\n",
      "   6. Country\n",
      "   7. Pack_Size\n",
      "   8. Material\n",
      "   9. Material_Description\n",
      "  10. QTY\n",
      "  11. Section\n",
      "  12. Product_Family\n",
      "  13. Common_Unique\n",
      "  14. Total_Lead_Time\n",
      "  15. BUoM\n",
      "  16. Model\n",
      "  17. Resource_ID\n",
      "  18. Resource_Description\n",
      "  19. Batch_Size\n",
      "\n",
      "Each market SKU has complete hierarchical BOM with Packing -> Assembly -> Filling!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"PER-SKU PEGGING SUMMARY\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(f\"\\nFILE: Material_pegging_SKU_2_BOM.xlsx\")\n",
    "print(f\"\\nTOTAL SKU PEGGING SHEETS: {len(sku_pegging_sheets)}\")\n",
    "\n",
    "print(f\"\\nSHEET STRUCTURE (Per Market SKU):\")\n",
    "print(f\"  Level 1 (Packing): Market SKU materials\")\n",
    "print(f\"  Separator: 0 (Product_ID column only)\")\n",
    "print(f\"  Level 2 (Assembly): Assembly materials\")\n",
    "print(f\"  Separator: 0 (Product_ID column only)\")\n",
    "print(f\"  Level 3 (Filling): Filling materials\")\n",
    "\n",
    "print(f\"\\nCOLUMNS (19 total):\")\n",
    "for idx, col in enumerate(output_cols, 1):\n",
    "    print(f\"  {idx:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nEach market SKU has complete hierarchical BOM with Packing -> Assembly -> Filling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
